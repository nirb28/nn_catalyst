{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nirb28/nn_catalyst/blob/main/src/different_approaches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYFVi5Gn2QjN",
    "outputId": "b90ea937-1d4a-457a-aae3-acba9bb8b35c"
   },
   "source": [
    "import os, sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Colab!\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    from google.colab import userdata\n",
    "else:\n",
    "    print(\"Not running in Colab.\")\n",
    "\n",
    "def resolve_path_gdrive(relativePath):\n",
    "    if os.path.exists('/content/drive'):\n",
    "        return '/content/drive/MyDrive/work/gdrive-workspaces/git/nn_catalyst/' + relativePath\n",
    "    else:\n",
    "        from utils import get_project_root\n",
    "        return get_project_root() + \"/\" + relativePath"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ak7hhtSw2QjQ"
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Load the data\n",
    "descriptors_path = 'descriptors.csv'\n",
    "targets_path = 'compiled_data.csv'"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L9Kr2K0S2QjQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d2be3ea3-f03a-4751-f46d-a11cd03ee72a"
   },
   "source": [
    "descriptors_df = pd.read_csv(resolve_path_gdrive(descriptors_path))\n",
    "targets_df = pd.read_csv(resolve_path_gdrive(targets_path))"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWWSEdLT2QjR",
    "outputId": "e87a2011-55f4-4b38-de64-8fa3ca561a44"
   },
   "source": [
    "# Show sample rows\n",
    "print(\"\\nSample Rows from Descriptors DataFrame:\")\n",
    "print(descriptors_df.head())\n",
    "print(\"\\nSample Rows from Targets DataFrame:\")\n",
    "print(targets_df.head())"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vJxB6lh2QjR",
    "outputId": "e2bdb5af-924c-4d46-c8a1-b63df9d3d1d1"
   },
   "source": [
    "# selected column\n",
    "selected_cols=[5, 14, 15, 23, 24, 25]\n",
    "number_of_target_cols = len(selected_cols)\n",
    "selected_cols.insert(0, 0)\n",
    "targets_df = targets_df.iloc[:, selected_cols]\n",
    "print(targets_df)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vY4vLqXb2QjR",
    "ExecuteTime": {
     "end_time": "2024-09-22T00:07:48.094414Z",
     "start_time": "2024-09-22T00:07:47.765137Z"
    }
   },
   "source": [
    "# Keep only numeric columns\n",
    "descriptors_numeric = descriptors_df.select_dtypes(include=['number'])\n",
    "targets_numeric = targets_df.select_dtypes(include=['number'])\n",
    "\n",
    "# Merge the numeric dataframes on the common label column\n",
    "numeric_data = pd.merge(descriptors_numeric, targets_numeric, left_on='Label', right_on='mol_num')\n",
    "numeric_data = numeric_data.drop(columns=['Label', 'mol_num'])\n",
    "\n",
    "# Separate features and targets\n",
    "X = numeric_data.iloc[:, :-number_of_target_cols]  # Assuming the last 30 columns are targets\n",
    "y = numeric_data.iloc[:, -number_of_target_cols:]"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "APUS1Jw32QjS",
    "ExecuteTime": {
     "end_time": "2024-09-22T00:08:06.570664Z",
     "start_time": "2024-09-22T00:08:05.219444Z"
    }
   },
   "source": [
    "# Apply variance threshold\n",
    "selector = VarianceThreshold()\n",
    "X_high_variance = selector.fit_transform(X)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = X_high_variance\n",
    "y = y.values\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler_X = StandardScaler().fit(X_train)\n",
    "scaler_y = StandardScaler().fit(y_train)\n",
    "\n",
    "X_train = scaler_X.transform(X_train)\n",
    "X_val = scaler_X.transform(X_val)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "y_train = scaler_y.transform(y_train)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32, device=device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32, device=device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MQGGaGmq2QjS",
    "ExecuteTime": {
     "end_time": "2024-09-22T00:08:11.148453Z",
     "start_time": "2024-09-22T00:08:11.134507Z"
    }
   },
   "source": [
    "# Create DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the individual model class\n",
    "class SingleTargetNet(nn.Module):\n",
    "    def __init__(self, input_size, dropout_rate=0.5):\n",
    "        super(SingleTargetNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 1)\n",
    "        self.fc_skip = nn.Linear(1024, 512)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.bn1(self.fc1(x)))\n",
    "        x1 = self.dropout(x1)\n",
    "\n",
    "        x2 = F.relu(self.bn2(self.fc2(x1)))\n",
    "        x2 = self.dropout(x2)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 += self.fc_skip(x1)\n",
    "\n",
    "        x3 = self.fc3(x2)\n",
    "        return x3\n",
    "\n",
    "def get_target5model():\n",
    "    # Define the model\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(X_train.shape[1], 1024),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(256, 1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "class RegressionNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RegressionNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wMcKunc12QjS",
    "ExecuteTime": {
     "end_time": "2024-09-22T00:08:38.960526Z",
     "start_time": "2024-09-22T00:08:38.947074Z"
    }
   },
   "source": [
    "# Function to train and evaluate individual models\n",
    "def train_and_evaluate(target_index, model):\n",
    "    model.to(device=device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    patience_counter = 0\n",
    "    num_epochs = 150\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, targets[:, target_index])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Target {target_index} - Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, targets[:, target_index])\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f'Target {target_index} - Validation Loss: {val_loss}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), resolve_path_gdrive(f'{selected_cols[target_index+1]}_{type(model).__name__}_model.pth'))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 15:\n",
    "                print(f'Target {target_index} - Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(resolve_path_gdrive(f'{selected_cols[target_index+1]}_{type(model).__name__}_model.pth')))\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, targets[:, target_index])\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f'Target {target_index} - Test Loss: {test_loss}')\n",
    "\n",
    "    return model, test_loss"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NN-lXmV2QjT",
    "outputId": "5d9908cf-6758-4b27-a84c-a1be1c2e15ce",
    "ExecuteTime": {
     "end_time": "2024-09-22T00:08:40.316889Z",
     "start_time": "2024-09-22T00:08:40.309561Z"
    }
   },
   "source": [
    "# Train and evaluate individual models for each target\n",
    "test_losses = []\n",
    "models = []\n",
    "try_models = [SingleTargetNet(X_train.shape[1]), RegressionNetwork(X_train.shape[1], 512, 1), get_target5model()]\n",
    "\n",
    "for target_index in range(y_train.shape[1]):\n",
    "    for a_model in try_models:\n",
    "        model, test_loss = train_and_evaluate(target_index, a_model)\n",
    "        models.append(model)\n",
    "        test_losses.append(test_loss)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "models"
   ],
   "metadata": {
    "id": "fELuFP9iFXHU",
    "outputId": "d07ef13b-1c73-44a7-e722-7a7abeece943",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ACMqmYbr2QjT",
    "ExecuteTime": {
     "end_time": "2024-09-22T00:08:44.106307Z",
     "start_time": "2024-09-22T00:08:44.092802Z"
    }
   },
   "source": [
    "# Prepare DataFrames for train, validation, and test predictions\n",
    "train_df = pd.DataFrame()\n",
    "val_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "r2_scores, rmse_scores, mae_scores = [], [], []\n",
    "\n",
    "def compute_stats(target_index, df):\n",
    "    print(df)\n",
    "    observed_col = f'Observed_{target_index}'\n",
    "    predicted_col = f'Predicted_{target_index}'\n",
    "\n",
    "    # Calculate metrics\n",
    "    observed = df[observed_col]\n",
    "    predicted = df[predicted_col]\n",
    "    r2 = r2_score(observed, predicted)\n",
    "    rmse = mean_squared_error(observed, predicted, squared=False)\n",
    "    mae = mean_absolute_error(observed, predicted)\n",
    "    return r2, rmse, mae"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T00:08:54.693833Z",
     "start_time": "2024-09-22T00:08:47.796939Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hmYa3OGsAIUC",
    "outputId": "68a3e8fb-47e1-4a02-ec2f-19a3674d4fd8"
   },
   "cell_type": "code",
   "source": [
    "def evaluate(target_index, model):\n",
    "    # Make predictions on the train, validation, and test sets\n",
    "    model.cpu().eval()\n",
    "    with torch.no_grad():\n",
    "        y_train_pred = model(X_train_tensor.cpu()).numpy()\n",
    "        y_val_pred = model(X_val_tensor.cpu()).numpy()\n",
    "        y_test_pred = model(X_test_tensor.cpu()).numpy()\n",
    "\n",
    "    # Inverse transform the predictions and targets to their original scale\n",
    "    y_train_pred_orig = scaler_y.inverse_transform(np.concatenate([np.zeros((y_train_pred.shape[0], target_index)), y_train_pred, np.zeros((y_train_pred.shape[0], y_train.shape[1] - target_index - 1))], axis=1))[:, target_index]\n",
    "    y_val_pred_orig = scaler_y.inverse_transform(np.concatenate([np.zeros((y_val_pred.shape[0], target_index)), y_val_pred, np.zeros((y_val_pred.shape[0], y_val.shape[1] - target_index - 1))], axis=1))[:, target_index]\n",
    "    y_test_pred_orig = scaler_y.inverse_transform(np.concatenate([np.zeros((y_test_pred.shape[0], target_index)), y_test_pred, np.zeros((y_test_pred.shape[0], y_test.shape[1] - target_index - 1))], axis=1))[:, target_index]\n",
    "\n",
    "    y_train_orig = scaler_y.inverse_transform(y_train)[:, target_index]\n",
    "    y_val_orig = scaler_y.inverse_transform(y_val)[:, target_index]\n",
    "    y_test_orig = scaler_y.inverse_transform(y_test)[:, target_index]\n",
    "\n",
    "    # Create dataframes for the predictions and actual values\n",
    "    train_df[f'Observed_{target_index}'] = y_train_orig\n",
    "    train_df[f'Predicted_{target_index}'] = y_train_pred_orig\n",
    "\n",
    "    val_df[f'Observed_{target_index}'] = y_val_orig\n",
    "    val_df[f'Predicted_{target_index}'] = y_val_pred_orig\n",
    "\n",
    "    test_df[f'Observed_{target_index}'] = y_test_orig\n",
    "    test_df[f'Predicted_{target_index}'] = y_test_pred_orig\n",
    "\n",
    "    # Create and insert parity plots for train, validation, and test sets\n",
    "    r2, rmse, mae = compute_stats(target_index, train_df)\n",
    "    r2_scores.append(r2)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "for target_index in range(y_train.shape[1]):\n",
    "    for model_type in try_models:\n",
    "        model = model_type\n",
    "        model.load_state_dict(torch.load(resolve_path_gdrive(f'{selected_cols[target_index+1]}_{type(model_type).__name__}_model.pth')))\n",
    "        evaluate(target_index, model)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uNp1a-3R2QjU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "63496d13-d1c2-4e7c-eca5-3cb1cc0df580"
   },
   "source": [
    "r2_scores, rmse_scores, mae_scores"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "6hqYkO8kAIUD"
   },
   "cell_type": "code",
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
