{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom Dataset class\n",
    "class MultiTargetDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Define the Neural Network model\n",
    "class SequentialRegressor(pl.LightningModule):\n",
    "    def __init__(self, input_dim, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "# Function to train model for one target\n",
    "def train_single_target(X_train, X_val, y_train, y_val, input_dim):\n",
    "    # Create datasets\n",
    "    train_dataset = MultiTargetDataset(X_train, y_train)\n",
    "    val_dataset = MultiTargetDataset(X_val, y_val)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SequentialRegressor(input_dim)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        callbacks=[early_stopping],\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "        accelerator='auto',\n",
    "        devices=1\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Main training loop\n",
    "def sequential_training(df, num_features=1479, num_targets=29):\n",
    "    \"\"\"\n",
    "    Main function to perform sequential training for all targets\n",
    "    \"\"\"\n",
    "    # Split features and targets\n",
    "    X = df.iloc[:, :num_features].values\n",
    "    y = df.iloc[:, num_features:num_features+num_targets].values\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize DataFrame for predictions\n",
    "    final_predictions = pd.DataFrame()\n",
    "    \n",
    "    # Current feature matrix\n",
    "    current_features = X_scaled.copy()\n",
    "    \n",
    "    # Loop through each target\n",
    "    for target_idx in range(num_targets):\n",
    "        print(f\"\\nTraining model for target {target_idx + 1}/{num_targets}\")\n",
    "        \n",
    "        # Get current target\n",
    "        current_target = y[:, target_idx].reshape(-1, 1)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            current_features, \n",
    "            current_target, \n",
    "            test_size=0.2, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model = train_single_target(\n",
    "            X_train, \n",
    "            X_val, \n",
    "            y_train, \n",
    "            y_val, \n",
    "            input_dim=current_features.shape[1]\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(torch.tensor(current_features, dtype=torch.float32))\n",
    "            predictions = predictions.numpy()\n",
    "        \n",
    "        # Add predictions to DataFrame\n",
    "        final_predictions[f'target_{target_idx+1}_pred'] = predictions.flatten()\n",
    "        \n",
    "        # Add predictions to feature matrix for next target\n",
    "        current_features = np.hstack([current_features, predictions])\n",
    "        \n",
    "    return final_predictions\n",
    "\n",
    "# Example usage\n",
    "\"\"\"\n",
    "# Load your data\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Run sequential training\n",
    "predictions = sequential_training(df)\n",
    "\n",
    "# Save predictions\n",
    "predictions.to_csv('predictions.csv', index=False)\n",
    "\"\"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "write a jupyter notebook that trains a model in pytorch lightning. the input dataframe has 1479 features and 29 targets at the end. The training loop starts with the first target, trains the model, predicts all the values and appends the predicted column at the end. For the next target it will use the original 1479 features and the new predicted column. This will continue till we have created a model for all the 29 targets. \n",
    "\n",
    "https://claude.site/artifacts/992175a9-532f-408f-8329-84322a2f2d25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
