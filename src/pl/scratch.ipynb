{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nirb28/nn_catalyst/blob/main/src/pl/scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "99af9e205d508ca4"
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Colab!\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    !pip install pytorch_lightning\n",
    "    !pip install torchmetrics\n",
    "else:\n",
    "    print(\"Not running in Colab.\")"
   ],
   "metadata": {
    "id": "AKO5oAFESNmd",
    "ExecuteTime": {
     "end_time": "2024-11-12T01:10:15.468194Z",
     "start_time": "2024-11-12T01:10:15.454042Z"
    }
   },
   "id": "AKO5oAFESNmd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "febc06fcc3bc3638",
    "ExecuteTime": {
     "end_time": "2024-11-12T01:10:40.049480Z",
     "start_time": "2024-11-12T01:10:18.124651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "DEBUG = False\n",
    "# Training hyperparameters\n",
    "INPUT_SIZE = 1479\n",
    "NUM_TARGETS = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 150\n",
    "NUM_WORKERS = 0\n",
    "# Compute related\n",
    "ACCELERATOR = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICES = [0]\n",
    "PRECISION = 32\n",
    "CHECKPOINTS_FOLDER = \"/checkpoints/stn_2_r1\""
   ],
   "id": "febc06fcc3bc3638",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "25fba0fd40809552",
    "outputId": "8d2dccb9-18d3-4015-f7ec-d3dc9f60ad7c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-11-12T01:11:04.248811Z",
     "start_time": "2024-11-12T01:11:04.217134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import random_split\n",
    "import pytorch_lightning as pl\n",
    "import torch, math, os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "seed = 1234\n",
    "pl.seed_everything(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def resolve_path_gdrive(relativePath):\n",
    "    if os.path.exists('/content/drive'):\n",
    "        return '/content/drive/MyDrive/work/gdrive-workspaces/git/nn_catalyst/' + relativePath\n",
    "    else:\n",
    "        from utils import get_project_root\n",
    "        return get_project_root() + \"/\" + relativePath\n",
    "\n",
    "print(f\"Root project folder is at {resolve_path_gdrive('.')}\")"
   ],
   "id": "25fba0fd40809552",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root project folder is at D:\\ds\\sync\\gdrive\\work\\gdrive-workspaces\\git\\nn_catalyst/.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "88eb903e9b5a6f6f",
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T01:11:06.527160Z",
     "start_time": "2024-11-12T01:11:06.517649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir f\"/content/drive/MyDrive/work/gdrive-workspaces/git/nn_catalyst/checkpoints/{CHECKPOINTS_FOLDER}/lightning_logs\""
   ],
   "id": "88eb903e9b5a6f6f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "id": "31982c159904e778",
    "ExecuteTime": {
     "end_time": "2024-11-12T01:11:18.401503Z",
     "start_time": "2024-11-12T01:11:08.665322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "datafile='src/pl/merged_data_last29_reordered_byR2.csv'\n",
    "max_rows=None\n",
    "xy_orig = np.loadtxt(resolve_path_gdrive(datafile), delimiter=',', skiprows=1, dtype=float, max_rows=max_rows)"
   ],
   "id": "31982c159904e778",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "2c407a8a7a5bc7db",
    "ExecuteTime": {
     "end_time": "2024-11-12T01:11:23.705843Z",
     "start_time": "2024-11-12T01:11:23.678614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BaseModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.r2 = torchmetrics.R2Score()\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"train_loss\": loss,\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        accuracy = self.r2(scores, y)\n",
    "        self.log(\"train_acc\", accuracy, prog_bar=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_average = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"validation_epoch_average\", epoch_average)\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, scores, y = self._common_step(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x)\n",
    "        loss = self.loss_fn(scores, y)\n",
    "        if DEBUG == True:\n",
    "            print(f\"loss: {loss}, len: {len(y)}\")\n",
    "        return loss, scores, y\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        scores = self.forward(x)\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(lr=self.lr, params=self.parameters())\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, min_lr=0.000000001, threshold=0.001)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "class SingleTargetNet(BaseModel):\n",
    "\n",
    "    def __init__(self, input_size=INPUT_SIZE, learning_rate=0.001, dropout_rate=0.5, target=1):\n",
    "        super(SingleTargetNet, self).__init__()\n",
    "        self.lr = learning_rate\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 1)\n",
    "        self.fc_skip = nn.Linear(1024, 512)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.bn1(self.fc1(x)))\n",
    "        x1 = self.dropout(x1)\n",
    "\n",
    "        x2 = F.relu(self.bn2(self.fc2(x1)))\n",
    "        x2 = self.dropout(x2)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 += self.fc_skip(x1)\n",
    "\n",
    "        x3 = self.fc3(x2)\n",
    "        return x3\n"
   ],
   "id": "2c407a8a7a5bc7db",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# prompt: write a function that takes in a numpy array and splits it into train, test and validation. it then scales all the data including the target columns. finally create a dataset and dataloader for all the 3 and wrap it into a datamodule\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class CatalystDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Split data into train, validation, and test sets\n",
    "        X = self.data[:, :-1]\n",
    "        y = self.data[:, -1]\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "        # Scale data using StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "        y_train = scaler.fit_transform(y_train)\n",
    "        y_val = scaler.transform(y_val)\n",
    "        y_test = scaler.transform(y_test)\n",
    "\n",
    "        # Create numpy arrays for the data\n",
    "        self.train_data = np.concatenate((X_train, y_train), axis=1)\n",
    "        self.val_data = np.concatenate((X_val, y_val), axis=1)\n",
    "        self.test_data = np.concatenate((X_test, y_test), axis=1)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Create datasets\n",
    "        self.train_dataset = CatalystDataset(self.train_data)\n",
    "        self.val_dataset = CatalystDataset(self.val_data)\n",
    "        self.test_dataset = CatalystDataset(self.test_data)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "class CatalystDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.x = torch.tensor(self.data[:, :-1], dtype=torch.float32)\n",
    "        #self.y = torch.tensor(self.data[:, -1], dtype=torch.float32)\n",
    "        self.y = torch.unsqueeze(\n",
    "            torch.tensor(self.data[:, -1], dtype=torch.float32), 1).float()  # size [n_samples, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ],
   "metadata": {
    "id": "KsMrlWgAD9mj",
    "ExecuteTime": {
     "end_time": "2024-11-12T01:11:34.374810Z",
     "start_time": "2024-11-12T01:11:26.353923Z"
    }
   },
   "id": "KsMrlWgAD9mj",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "104ba4b8ac4936f0",
    "ExecuteTime": {
     "end_time": "2024-11-12T01:22:04.828553Z",
     "start_time": "2024-11-12T01:11:54.742802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn, optim\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "def prepare_data_module(xy):\n",
    "    dm = CatalystDataModule(data=xy)\n",
    "    dm.prepare_data()\n",
    "    dm.setup()\n",
    "    return dm\n",
    "\n",
    "def prepare_trainer(target, num_epochs=NUM_EPOCHS):\n",
    "    tensorboard = TensorBoardLogger(resolve_path_gdrive(f'{CHECKPOINTS_FOLDER}/lightning_logs'), name=f\"{target}\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=resolve_path_gdrive(f'{CHECKPOINTS_FOLDER}/{target}'),\n",
    "        filename='{epoch:02d}-{val_loss:.2f}',\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    )\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=ACCELERATOR,\n",
    "        devices=1,\n",
    "        min_epochs=1,\n",
    "        max_epochs=num_epochs,\n",
    "        precision=PRECISION,\n",
    "        fast_dev_run=False,\n",
    "        enable_checkpointing=True,\n",
    "        enable_progress_bar=True,\n",
    "        log_every_n_steps=20,\n",
    "        logger=tensorboard,\n",
    "        callbacks=[checkpoint_callback, lr_monitor, RichProgressBar(),\n",
    "                EarlyStopping(monitor=\"train_loss\", patience=10, verbose=True, mode=\"min\")]\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "def prepare_model(input_size):\n",
    "    model = SingleTargetNet (\n",
    "        input_size=input_size,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def iterate_all_targets(xy_data, total_targets):\n",
    "    total_cols = xy_data.shape[1]\n",
    "    for target_num in range(1, total_targets+1):\n",
    "        target_col_start = total_cols - (total_targets - target_num)\n",
    "        print(f'Target {target_num}, target_col {target_col_start}')\n",
    "        xy_data = torch.from_numpy(xy_orig[:,:target_col_start]).float()  # size [n_samples, n_features]\n",
    "        dm = prepare_data_module(xy_data)\n",
    "        model = prepare_model(input_size=dm.train_dataset.x.shape[1])\n",
    "        trainer = prepare_trainer(target=target_num, num_epochs=NUM_EPOCHS)\n",
    "        trainer.fit(model, dm)\n",
    "        trainer.validate(model, dm)\n",
    "        trainer.test(model, dm)\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\") # to make lightning happy\n",
    "if __name__ == \"__main__\":\n",
    "    iterate_all_targets(xy_orig, total_targets=5)"
   ],
   "id": "104ba4b8ac4936f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 1, target_col 1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory D:\\ds\\sync\\gdrive\\work\\gdrive-workspaces\\git\\nn_catalyst\\checkpoints\\stn_2_r1\\1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mName   \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mType       \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mParams\u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mMode \u001B[0m\u001B[1;35m \u001B[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001B[2m \u001B[0m\u001B[2m0\u001B[0m\u001B[2m \u001B[0m│ r2      │ R2Score     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m1\u001B[0m\u001B[2m \u001B[0m│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m2\u001B[0m\u001B[2m \u001B[0m│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m3\u001B[0m\u001B[2m \u001B[0m│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m4\u001B[0m\u001B[2m \u001B[0m│ fc2     │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m5\u001B[0m\u001B[2m \u001B[0m│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m6\u001B[0m\u001B[2m \u001B[0m│ fc3     │ Linear      │    513 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m7\u001B[0m\u001B[2m \u001B[0m│ fc_skip │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m8\u001B[0m\u001B[2m \u001B[0m│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ r2      │ R2Score     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ fc2     │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ fc3     │ Linear      │    513 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>│ fc_skip │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mTrainable params\u001B[0m: 2.6 M                                                                                            \n",
       "\u001B[1mNon-trainable params\u001B[0m: 0                                                                                            \n",
       "\u001B[1mTotal params\u001B[0m: 2.6 M                                                                                                \n",
       "\u001B[1mTotal estimated model params size (MB)\u001B[0m: 10                                                                         \n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 10                                                                         \n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61f10bcc0aea458ab0e8734b868a58c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 2.240\n",
      "Epoch 0, global step 36: 'val_loss' reached 0.55690 (best 0.55690), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=00-val_loss=0.56.ckpt' as top 1\n",
      "Metric train_loss improved by 1.719 >= min_delta = 0.0. New best score: 0.521\n",
      "Epoch 1, global step 72: 'val_loss' reached 0.38745 (best 0.38745), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=01-val_loss=0.39.ckpt' as top 1\n",
      "Metric train_loss improved by 0.092 >= min_delta = 0.0. New best score: 0.429\n",
      "Epoch 2, global step 108: 'val_loss' reached 0.33477 (best 0.33477), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=02-val_loss=0.33.ckpt' as top 1\n",
      "Metric train_loss improved by 0.058 >= min_delta = 0.0. New best score: 0.371\n",
      "Epoch 3, global step 144: 'val_loss' reached 0.30808 (best 0.30808), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=03-val_loss=0.31.ckpt' as top 1\n",
      "Metric train_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.338\n",
      "Epoch 4, global step 180: 'val_loss' reached 0.28419 (best 0.28419), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=04-val_loss=0.28.ckpt' as top 1\n",
      "Metric train_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.305\n",
      "Epoch 5, global step 216: 'val_loss' reached 0.27105 (best 0.27105), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=05-val_loss=0.27.ckpt' as top 1\n",
      "Metric train_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.288\n",
      "Epoch 6, global step 252: 'val_loss' reached 0.25763 (best 0.25763), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=06-val_loss=0.26.ckpt' as top 1\n",
      "Metric train_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.268\n",
      "Epoch 7, global step 288: 'val_loss' reached 0.24314 (best 0.24314), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=07-val_loss=0.24.ckpt' as top 1\n",
      "Metric train_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.251\n",
      "Epoch 8, global step 324: 'val_loss' reached 0.23875 (best 0.23875), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=08-val_loss=0.24.ckpt' as top 1\n",
      "Metric train_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.236\n",
      "Epoch 9, global step 360: 'val_loss' reached 0.23025 (best 0.23025), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=09-val_loss=0.23.ckpt' as top 1\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.230\n",
      "Epoch 10, global step 396: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.221\n",
      "Epoch 11, global step 432: 'val_loss' reached 0.22631 (best 0.22631), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=11-val_loss=0.23.ckpt' as top 1\n",
      "Metric train_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.210\n",
      "Epoch 12, global step 468: 'val_loss' reached 0.22457 (best 0.22457), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=12-val_loss=0.22.ckpt' as top 1\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.203\n",
      "Epoch 13, global step 504: 'val_loss' reached 0.21566 (best 0.21566), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=13-val_loss=0.22.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.199\n",
      "Epoch 14, global step 540: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.190\n",
      "Epoch 15, global step 576: 'val_loss' reached 0.21481 (best 0.21481), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=15-val_loss=0.21.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.186\n",
      "Epoch 16, global step 612: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.181\n",
      "Epoch 17, global step 648: 'val_loss' reached 0.21382 (best 0.21382), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=17-val_loss=0.21.ckpt' as top 1\n",
      "Epoch 18, global step 684: 'val_loss' reached 0.21346 (best 0.21346), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=18-val_loss=0.21.ckpt' as top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.176\n",
      "Epoch 19, global step 720: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.172\n",
      "Epoch 20, global step 756: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.170\n",
      "Epoch 21, global step 792: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.166\n",
      "Epoch 22, global step 828: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.163\n",
      "Epoch 23, global step 864: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.160\n",
      "Epoch 24, global step 900: 'val_loss' was not in top 1\n",
      "Epoch 25, global step 936: 'val_loss' reached 0.21253 (best 0.21253), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=25-val_loss=0.21.ckpt' as top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.154\n",
      "Epoch 26, global step 972: 'val_loss' reached 0.20249 (best 0.20249), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=26-val_loss=0.20.ckpt' as top 1\n",
      "Epoch 27, global step 1008: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.151\n",
      "Epoch 28, global step 1044: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.149\n",
      "Epoch 29, global step 1080: 'val_loss' reached 0.19588 (best 0.19588), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=29-val_loss=0.20.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.145\n",
      "Epoch 30, global step 1116: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.141\n",
      "Epoch 31, global step 1152: 'val_loss' reached 0.18671 (best 0.18671), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=31-val_loss=0.19.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.139\n",
      "Epoch 32, global step 1188: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.137\n",
      "Epoch 33, global step 1224: 'val_loss' was not in top 1\n",
      "Epoch 34, global step 1260: 'val_loss' reached 0.18449 (best 0.18449), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=34-val_loss=0.18.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.136\n",
      "Epoch 35, global step 1296: 'val_loss' reached 0.18318 (best 0.18318), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=35-val_loss=0.18.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.136\n",
      "Epoch 36, global step 1332: 'val_loss' reached 0.18255 (best 0.18255), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=36-val_loss=0.18.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.132\n",
      "Epoch 37, global step 1368: 'val_loss' reached 0.17865 (best 0.17865), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=37-val_loss=0.18.ckpt' as top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.130\n",
      "Epoch 38, global step 1404: 'val_loss' reached 0.17705 (best 0.17705), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=38-val_loss=0.18.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.129\n",
      "Epoch 39, global step 1440: 'val_loss' reached 0.17633 (best 0.17633), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=39-val_loss=0.18.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.128\n",
      "Epoch 40, global step 1476: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.122\n",
      "Epoch 41, global step 1512: 'val_loss' reached 0.17400 (best 0.17400), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=41-val_loss=0.17.ckpt' as top 1\n",
      "Epoch 42, global step 1548: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.122\n",
      "Epoch 43, global step 1584: 'val_loss' reached 0.17134 (best 0.17134), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=43-val_loss=0.17.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.122\n",
      "Epoch 44, global step 1620: 'val_loss' was not in top 1\n",
      "Epoch 45, global step 1656: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.119\n",
      "Epoch 46, global step 1692: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.115\n",
      "Epoch 47, global step 1728: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.114\n",
      "Epoch 48, global step 1764: 'val_loss' was not in top 1\n",
      "Epoch 49, global step 1800: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.111\n",
      "Epoch 50, global step 1836: 'val_loss' reached 0.16950 (best 0.16950), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=50-val_loss=0.17.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.107\n",
      "Epoch 51, global step 1872: 'val_loss' was not in top 1\n",
      "Epoch 52, global step 1908: 'val_loss' reached 0.16324 (best 0.16324), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=52-val_loss=0.16.ckpt' as top 1\n",
      "Epoch 53, global step 1944: 'val_loss' was not in top 1\n",
      "Epoch 54, global step 1980: 'val_loss' was not in top 1\n",
      "Epoch 55, global step 2016: 'val_loss' was not in top 1\n",
      "Epoch 56, global step 2052: 'val_loss' was not in top 1\n",
      "Epoch 57, global step 2088: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.103\n",
      "Epoch 58, global step 2124: 'val_loss' was not in top 1\n",
      "Epoch 59, global step 2160: 'val_loss' reached 0.16289 (best 0.16289), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=59-val_loss=0.16.ckpt' as top 1\n",
      "Epoch 60, global step 2196: 'val_loss' reached 0.16138 (best 0.16138), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=60-val_loss=0.16.ckpt' as top 1\n",
      "Epoch 61, global step 2232: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.101\n",
      "Epoch 62, global step 2268: 'val_loss' was not in top 1\n",
      "Epoch 63, global step 2304: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.101\n",
      "Epoch 64, global step 2340: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.098\n",
      "Epoch 65, global step 2376: 'val_loss' was not in top 1\n",
      "Epoch 66, global step 2412: 'val_loss' reached 0.16035 (best 0.16035), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=66-val_loss=0.16.ckpt' as top 1\n",
      "Epoch 67, global step 2448: 'val_loss' was not in top 1\n",
      "Epoch 68, global step 2484: 'val_loss' was not in top 1\n",
      "Epoch 69, global step 2520: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.097\n",
      "Epoch 70, global step 2556: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.096\n",
      "Epoch 71, global step 2592: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.093\n",
      "Epoch 72, global step 2628: 'val_loss' was not in top 1\n",
      "Epoch 73, global step 2664: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.093\n",
      "Epoch 74, global step 2700: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.093\n",
      "Epoch 75, global step 2736: 'val_loss' was not in top 1\n",
      "Epoch 76, global step 2772: 'val_loss' was not in top 1\n",
      "Epoch 77, global step 2808: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.089\n",
      "Epoch 78, global step 2844: 'val_loss' reached 0.15469 (best 0.15469), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=78-val_loss=0.15.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.084\n",
      "Epoch 79, global step 2880: 'val_loss' reached 0.15194 (best 0.15194), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=79-val_loss=0.15.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.080\n",
      "Epoch 80, global step 2916: 'val_loss' reached 0.15117 (best 0.15117), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=80-val_loss=0.15.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.078\n",
      "Epoch 81, global step 2952: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.077\n",
      "Epoch 82, global step 2988: 'val_loss' reached 0.15098 (best 0.15098), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=82-val_loss=0.15.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.075\n",
      "Epoch 83, global step 3024: 'val_loss' reached 0.14999 (best 0.14999), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=83-val_loss=0.15.ckpt' as top 1\n",
      "Epoch 84, global step 3060: 'val_loss' reached 0.14867 (best 0.14867), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=84-val_loss=0.15.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.073\n",
      "Epoch 85, global step 3096: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.072\n",
      "Epoch 86, global step 3132: 'val_loss' was not in top 1\n",
      "Epoch 87, global step 3168: 'val_loss' was not in top 1\n",
      "Epoch 88, global step 3204: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.071\n",
      "Epoch 89, global step 3240: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.070\n",
      "Epoch 90, global step 3276: 'val_loss' reached 0.14766 (best 0.14766), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=90-val_loss=0.15.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.069\n",
      "Epoch 91, global step 3312: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.069\n",
      "Epoch 92, global step 3348: 'val_loss' was not in top 1\n",
      "Epoch 93, global step 3384: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.068\n",
      "Epoch 94, global step 3420: 'val_loss' was not in top 1\n",
      "Epoch 95, global step 3456: 'val_loss' was not in top 1\n",
      "Epoch 96, global step 3492: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.068\n",
      "Epoch 97, global step 3528: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.068\n",
      "Epoch 98, global step 3564: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.068\n",
      "Epoch 99, global step 3600: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.065\n",
      "Epoch 100, global step 3636: 'val_loss' was not in top 1\n",
      "Epoch 101, global step 3672: 'val_loss' was not in top 1\n",
      "Epoch 102, global step 3708: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.064\n",
      "Epoch 103, global step 3744: 'val_loss' was not in top 1\n",
      "Epoch 104, global step 3780: 'val_loss' was not in top 1\n",
      "Epoch 105, global step 3816: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.064\n",
      "Epoch 106, global step 3852: 'val_loss' was not in top 1\n",
      "Epoch 107, global step 3888: 'val_loss' was not in top 1\n",
      "Epoch 108, global step 3924: 'val_loss' was not in top 1\n",
      "Epoch 109, global step 3960: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.063\n",
      "Epoch 110, global step 3996: 'val_loss' reached 0.14759 (best 0.14759), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=110-val_loss=0.15.ckpt' as top 1\n",
      "Epoch 111, global step 4032: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.062\n",
      "Epoch 112, global step 4068: 'val_loss' was not in top 1\n",
      "Epoch 113, global step 4104: 'val_loss' was not in top 1\n",
      "Epoch 114, global step 4140: 'val_loss' was not in top 1\n",
      "Epoch 115, global step 4176: 'val_loss' reached 0.14753 (best 0.14753), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=115-val_loss=0.15.ckpt' as top 1\n",
      "Epoch 116, global step 4212: 'val_loss' reached 0.14752 (best 0.14752), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\1\\\\epoch=116-val_loss=0.15.ckpt' as top 1\n",
      "Epoch 117, global step 4248: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.062\n",
      "Epoch 118, global step 4284: 'val_loss' was not in top 1\n",
      "Epoch 119, global step 4320: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.062\n",
      "Epoch 120, global step 4356: 'val_loss' was not in top 1\n",
      "Epoch 121, global step 4392: 'val_loss' was not in top 1\n",
      "Epoch 122, global step 4428: 'val_loss' was not in top 1\n",
      "Epoch 123, global step 4464: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.062\n",
      "Epoch 124, global step 4500: 'val_loss' was not in top 1\n",
      "Epoch 125, global step 4536: 'val_loss' was not in top 1\n",
      "Epoch 126, global step 4572: 'val_loss' was not in top 1\n",
      "Epoch 127, global step 4608: 'val_loss' was not in top 1\n",
      "Epoch 128, global step 4644: 'val_loss' was not in top 1\n",
      "Epoch 129, global step 4680: 'val_loss' was not in top 1\n",
      "Epoch 130, global step 4716: 'val_loss' was not in top 1\n",
      "Epoch 131, global step 4752: 'val_loss' was not in top 1\n",
      "Epoch 132, global step 4788: 'val_loss' was not in top 1\n",
      "Epoch 133, global step 4824: 'val_loss' was not in top 1\n",
      "Monitored metric train_loss did not improve in the last 10 records. Best score: 0.062. Signaling Trainer to stop.\n",
      "Epoch 134, global step 4860: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c11bf92377d4be1b98d1a4b565df1a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m     Validate metric     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        val_loss         \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.1477288007736206    \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36mvalidation_epoch_average \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.14656338095664978   \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1477288007736206     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> validation_epoch_average  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14656338095664978    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed8e0a4a5af2447b96da11d04fb06a88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_loss        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.13833384215831757   \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13833384215831757    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 2, target_col 1505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: D:\\ds\\sync\\gdrive\\work\\gdrive-workspaces\\git\\nn_catalyst//checkpoints/stn_2_r1/lightning_logs\\2\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mName   \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mType       \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mParams\u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mMode \u001B[0m\u001B[1;35m \u001B[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001B[2m \u001B[0m\u001B[2m0\u001B[0m\u001B[2m \u001B[0m│ r2      │ R2Score     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m1\u001B[0m\u001B[2m \u001B[0m│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m2\u001B[0m\u001B[2m \u001B[0m│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m3\u001B[0m\u001B[2m \u001B[0m│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m4\u001B[0m\u001B[2m \u001B[0m│ fc2     │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m5\u001B[0m\u001B[2m \u001B[0m│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m6\u001B[0m\u001B[2m \u001B[0m│ fc3     │ Linear      │    513 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m7\u001B[0m\u001B[2m \u001B[0m│ fc_skip │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m8\u001B[0m\u001B[2m \u001B[0m│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ r2      │ R2Score     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ fc2     │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ fc3     │ Linear      │    513 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>│ fc_skip │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mTrainable params\u001B[0m: 2.6 M                                                                                            \n",
       "\u001B[1mNon-trainable params\u001B[0m: 0                                                                                            \n",
       "\u001B[1mTotal params\u001B[0m: 2.6 M                                                                                                \n",
       "\u001B[1mTotal estimated model params size (MB)\u001B[0m: 10                                                                         \n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 10                                                                         \n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be87ca2f04cb41fba67d37b8044964dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 2.136\n",
      "Epoch 0, global step 36: 'val_loss' reached 0.60492 (best 0.60492), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=00-val_loss=0.60.ckpt' as top 1\n",
      "Metric train_loss improved by 1.497 >= min_delta = 0.0. New best score: 0.639\n",
      "Epoch 1, global step 72: 'val_loss' reached 0.48948 (best 0.48948), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=01-val_loss=0.49.ckpt' as top 1\n",
      "Metric train_loss improved by 0.074 >= min_delta = 0.0. New best score: 0.565\n",
      "Epoch 2, global step 108: 'val_loss' reached 0.46307 (best 0.46307), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=02-val_loss=0.46.ckpt' as top 1\n",
      "Metric train_loss improved by 0.050 >= min_delta = 0.0. New best score: 0.515\n",
      "Epoch 3, global step 144: 'val_loss' reached 0.43985 (best 0.43985), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=03-val_loss=0.44.ckpt' as top 1\n",
      "Metric train_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.483\n",
      "Epoch 4, global step 180: 'val_loss' reached 0.41217 (best 0.41217), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=04-val_loss=0.41.ckpt' as top 1\n",
      "Metric train_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.451\n",
      "Epoch 5, global step 216: 'val_loss' reached 0.39547 (best 0.39547), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=05-val_loss=0.40.ckpt' as top 1\n",
      "Metric train_loss improved by 0.031 >= min_delta = 0.0. New best score: 0.420\n",
      "Epoch 6, global step 252: 'val_loss' reached 0.38307 (best 0.38307), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=06-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.023 >= min_delta = 0.0. New best score: 0.397\n",
      "Epoch 7, global step 288: 'val_loss' reached 0.36527 (best 0.36527), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=07-val_loss=0.37.ckpt' as top 1\n",
      "Metric train_loss improved by 0.021 >= min_delta = 0.0. New best score: 0.376\n",
      "Epoch 8, global step 324: 'val_loss' reached 0.35324 (best 0.35324), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=08-val_loss=0.35.ckpt' as top 1\n",
      "Metric train_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.363\n",
      "Epoch 9, global step 360: 'val_loss' reached 0.34619 (best 0.34619), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=09-val_loss=0.35.ckpt' as top 1\n",
      "Metric train_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.351\n",
      "Epoch 10, global step 396: 'val_loss' reached 0.33670 (best 0.33670), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=10-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.338\n",
      "Epoch 11, global step 432: 'val_loss' reached 0.33039 (best 0.33039), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=11-val_loss=0.33.ckpt' as top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.329\n",
      "Epoch 12, global step 468: 'val_loss' reached 0.32896 (best 0.32896), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=12-val_loss=0.33.ckpt' as top 1\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.321\n",
      "Epoch 13, global step 504: 'val_loss' reached 0.31987 (best 0.31987), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=13-val_loss=0.32.ckpt' as top 1\n",
      "Metric train_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.311\n",
      "Epoch 14, global step 540: 'val_loss' reached 0.31622 (best 0.31622), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=14-val_loss=0.32.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.307\n",
      "Epoch 15, global step 576: 'val_loss' reached 0.31332 (best 0.31332), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=15-val_loss=0.31.ckpt' as top 1\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.294\n",
      "Epoch 16, global step 612: 'val_loss' reached 0.30440 (best 0.30440), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=16-val_loss=0.30.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.293\n",
      "Epoch 17, global step 648: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.283\n",
      "Epoch 18, global step 684: 'val_loss' reached 0.30372 (best 0.30372), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=18-val_loss=0.30.ckpt' as top 1\n",
      "Epoch 19, global step 720: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.278\n",
      "Epoch 20, global step 756: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.272\n",
      "Epoch 21, global step 792: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.269\n",
      "Epoch 22, global step 828: 'val_loss' reached 0.29453 (best 0.29453), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=22-val_loss=0.29.ckpt' as top 1\n",
      "Metric train_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.259\n",
      "Epoch 23, global step 864: 'val_loss' reached 0.28899 (best 0.28899), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=23-val_loss=0.29.ckpt' as top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.256\n",
      "Epoch 24, global step 900: 'val_loss' reached 0.28700 (best 0.28700), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=24-val_loss=0.29.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.254\n",
      "Epoch 25, global step 936: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.250\n",
      "Epoch 26, global step 972: 'val_loss' was not in top 1\n",
      "Epoch 27, global step 1008: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.244\n",
      "Epoch 28, global step 1044: 'val_loss' reached 0.28569 (best 0.28569), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=28-val_loss=0.29.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.240\n",
      "Epoch 29, global step 1080: 'val_loss' reached 0.27760 (best 0.27760), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=29-val_loss=0.28.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.240\n",
      "Epoch 30, global step 1116: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.236\n",
      "Epoch 31, global step 1152: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.231\n",
      "Epoch 32, global step 1188: 'val_loss' was not in top 1\n",
      "Epoch 33, global step 1224: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.226\n",
      "Epoch 34, global step 1260: 'val_loss' was not in top 1\n",
      "Epoch 35, global step 1296: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.223\n",
      "Epoch 36, global step 1332: 'val_loss' reached 0.27664 (best 0.27664), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=36-val_loss=0.28.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.221\n",
      "Epoch 37, global step 1368: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.216\n",
      "Epoch 38, global step 1404: 'val_loss' was not in top 1\n",
      "Epoch 39, global step 1440: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.213\n",
      "Epoch 40, global step 1476: 'val_loss' was not in top 1\n",
      "Epoch 41, global step 1512: 'val_loss' reached 0.27510 (best 0.27510), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=41-val_loss=0.28.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.211\n",
      "Epoch 42, global step 1548: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.208\n",
      "Epoch 43, global step 1584: 'val_loss' reached 0.27461 (best 0.27461), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=43-val_loss=0.27.ckpt' as top 1\n",
      "Epoch 44, global step 1620: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.207\n",
      "Epoch 45, global step 1656: 'val_loss' was not in top 1\n",
      "Epoch 46, global step 1692: 'val_loss' was not in top 1\n",
      "Epoch 47, global step 1728: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.200\n",
      "Epoch 48, global step 1764: 'val_loss' reached 0.27287 (best 0.27287), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=48-val_loss=0.27.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.200\n",
      "Epoch 49, global step 1800: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.196\n",
      "Epoch 50, global step 1836: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.190\n",
      "Epoch 51, global step 1872: 'val_loss' was not in top 1\n",
      "Epoch 52, global step 1908: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.184\n",
      "Epoch 53, global step 1944: 'val_loss' was not in top 1\n",
      "Epoch 54, global step 1980: 'val_loss' was not in top 1\n",
      "Epoch 55, global step 2016: 'val_loss' was not in top 1\n",
      "Epoch 56, global step 2052: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.184\n",
      "Epoch 57, global step 2088: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.178\n",
      "Epoch 58, global step 2124: 'val_loss' reached 0.26987 (best 0.26987), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=58-val_loss=0.27.ckpt' as top 1\n",
      "Epoch 59, global step 2160: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.177\n",
      "Epoch 60, global step 2196: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.176\n",
      "Epoch 61, global step 2232: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.173\n",
      "Epoch 62, global step 2268: 'val_loss' was not in top 1\n",
      "Epoch 63, global step 2304: 'val_loss' was not in top 1\n",
      "Epoch 64, global step 2340: 'val_loss' was not in top 1\n",
      "Epoch 65, global step 2376: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.172\n",
      "Epoch 66, global step 2412: 'val_loss' was not in top 1\n",
      "Epoch 67, global step 2448: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.170\n",
      "Epoch 68, global step 2484: 'val_loss' was not in top 1\n",
      "Epoch 69, global step 2520: 'val_loss' was not in top 1\n",
      "Epoch 70, global step 2556: 'val_loss' reached 0.25396 (best 0.25396), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=70-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.018 >= min_delta = 0.0. New best score: 0.152\n",
      "Epoch 71, global step 2592: 'val_loss' reached 0.25112 (best 0.25112), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=71-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.150\n",
      "Epoch 72, global step 2628: 'val_loss' was not in top 1\n",
      "Epoch 73, global step 2664: 'val_loss' reached 0.25021 (best 0.25021), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=73-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.147\n",
      "Epoch 74, global step 2700: 'val_loss' reached 0.24985 (best 0.24985), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=74-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.145\n",
      "Epoch 75, global step 2736: 'val_loss' reached 0.24956 (best 0.24956), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=75-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.140\n",
      "Epoch 76, global step 2772: 'val_loss' reached 0.24915 (best 0.24915), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=76-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.138\n",
      "Epoch 77, global step 2808: 'val_loss' reached 0.24897 (best 0.24897), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=77-val_loss=0.25.ckpt' as top 1\n",
      "Epoch 78, global step 2844: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.137\n",
      "Epoch 79, global step 2880: 'val_loss' reached 0.24765 (best 0.24765), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=79-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.136\n",
      "Epoch 80, global step 2916: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.134\n",
      "Epoch 81, global step 2952: 'val_loss' reached 0.24621 (best 0.24621), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=81-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.134\n",
      "Epoch 82, global step 2988: 'val_loss' was not in top 1\n",
      "Epoch 83, global step 3024: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.129\n",
      "Epoch 84, global step 3060: 'val_loss' was not in top 1\n",
      "Epoch 85, global step 3096: 'val_loss' was not in top 1\n",
      "Epoch 86, global step 3132: 'val_loss' was not in top 1\n",
      "Epoch 87, global step 3168: 'val_loss' was not in top 1\n",
      "Epoch 88, global step 3204: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.128\n",
      "Epoch 89, global step 3240: 'val_loss' was not in top 1\n",
      "Epoch 90, global step 3276: 'val_loss' reached 0.24565 (best 0.24565), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=90-val_loss=0.25.ckpt' as top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.126\n",
      "Epoch 91, global step 3312: 'val_loss' was not in top 1\n",
      "Epoch 92, global step 3348: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.125\n",
      "Epoch 93, global step 3384: 'val_loss' reached 0.24562 (best 0.24562), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=93-val_loss=0.25.ckpt' as top 1\n",
      "Epoch 94, global step 3420: 'val_loss' reached 0.24510 (best 0.24510), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=94-val_loss=0.25.ckpt' as top 1\n",
      "Epoch 95, global step 3456: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.122\n",
      "Epoch 96, global step 3492: 'val_loss' was not in top 1\n",
      "Epoch 97, global step 3528: 'val_loss' reached 0.24509 (best 0.24509), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=97-val_loss=0.25.ckpt' as top 1\n",
      "Epoch 98, global step 3564: 'val_loss' reached 0.24478 (best 0.24478), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=98-val_loss=0.24.ckpt' as top 1\n",
      "Epoch 99, global step 3600: 'val_loss' was not in top 1\n",
      "Epoch 100, global step 3636: 'val_loss' reached 0.24388 (best 0.24388), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=100-val_loss=0.24.ckpt' as top 1\n",
      "Epoch 101, global step 3672: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.121\n",
      "Epoch 102, global step 3708: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.118\n",
      "Epoch 103, global step 3744: 'val_loss' was not in top 1\n",
      "Epoch 104, global step 3780: 'val_loss' reached 0.24250 (best 0.24250), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=104-val_loss=0.24.ckpt' as top 1\n",
      "Epoch 105, global step 3816: 'val_loss' was not in top 1\n",
      "Epoch 106, global step 3852: 'val_loss' was not in top 1\n",
      "Epoch 107, global step 3888: 'val_loss' was not in top 1\n",
      "Epoch 108, global step 3924: 'val_loss' was not in top 1\n",
      "Epoch 109, global step 3960: 'val_loss' was not in top 1\n",
      "Epoch 110, global step 3996: 'val_loss' reached 0.24183 (best 0.24183), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=110-val_loss=0.24.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.118\n",
      "Epoch 111, global step 4032: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.116\n",
      "Epoch 112, global step 4068: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.115\n",
      "Epoch 113, global step 4104: 'val_loss' was not in top 1\n",
      "Epoch 114, global step 4140: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.115\n",
      "Epoch 115, global step 4176: 'val_loss' was not in top 1\n",
      "Epoch 116, global step 4212: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.114\n",
      "Epoch 117, global step 4248: 'val_loss' reached 0.24153 (best 0.24153), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=117-val_loss=0.24.ckpt' as top 1\n",
      "Epoch 118, global step 4284: 'val_loss' reached 0.24136 (best 0.24136), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=118-val_loss=0.24.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.112\n",
      "Epoch 119, global step 4320: 'val_loss' reached 0.24115 (best 0.24115), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=119-val_loss=0.24.ckpt' as top 1\n",
      "Epoch 120, global step 4356: 'val_loss' was not in top 1\n",
      "Epoch 121, global step 4392: 'val_loss' was not in top 1\n",
      "Epoch 122, global step 4428: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.111\n",
      "Epoch 123, global step 4464: 'val_loss' was not in top 1\n",
      "Epoch 124, global step 4500: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.110\n",
      "Epoch 125, global step 4536: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.110\n",
      "Epoch 126, global step 4572: 'val_loss' reached 0.24111 (best 0.24111), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=126-val_loss=0.24.ckpt' as top 1\n",
      "Epoch 127, global step 4608: 'val_loss' reached 0.24008 (best 0.24008), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\2\\\\epoch=127-val_loss=0.24.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.109\n",
      "Epoch 128, global step 4644: 'val_loss' was not in top 1\n",
      "Epoch 129, global step 4680: 'val_loss' was not in top 1\n",
      "Epoch 130, global step 4716: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.109\n",
      "Epoch 131, global step 4752: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.109\n",
      "Epoch 132, global step 4788: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.109\n",
      "Epoch 133, global step 4824: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.108\n",
      "Epoch 134, global step 4860: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.107\n",
      "Epoch 135, global step 4896: 'val_loss' was not in top 1\n",
      "Epoch 136, global step 4932: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.106\n",
      "Epoch 137, global step 4968: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.105\n",
      "Epoch 138, global step 5004: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.104\n",
      "Epoch 139, global step 5040: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.103\n",
      "Epoch 140, global step 5076: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.102\n",
      "Epoch 141, global step 5112: 'val_loss' was not in top 1\n",
      "Epoch 142, global step 5148: 'val_loss' was not in top 1\n",
      "Epoch 143, global step 5184: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.102\n",
      "Epoch 144, global step 5220: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.101\n",
      "Epoch 145, global step 5256: 'val_loss' was not in top 1\n",
      "Epoch 146, global step 5292: 'val_loss' was not in top 1\n",
      "Epoch 147, global step 5328: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.100\n",
      "Epoch 148, global step 5364: 'val_loss' was not in top 1\n",
      "Epoch 149, global step 5400: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41d6acab935042d8a00cb896f160e315"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m     Validate metric     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        val_loss         \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.24125894904136658   \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36mvalidation_epoch_average \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.2405952513217926    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.24125894904136658    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> validation_epoch_average  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2405952513217926     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "160275ae92fd48fa90f80cdae307aec5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_loss        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.2837657332420349    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2837657332420349     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 3, target_col 1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: D:\\ds\\sync\\gdrive\\work\\gdrive-workspaces\\git\\nn_catalyst//checkpoints/stn_2_r1/lightning_logs\\3\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mName   \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mType       \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mParams\u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mMode \u001B[0m\u001B[1;35m \u001B[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001B[2m \u001B[0m\u001B[2m0\u001B[0m\u001B[2m \u001B[0m│ r2      │ R2Score     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m1\u001B[0m\u001B[2m \u001B[0m│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m2\u001B[0m\u001B[2m \u001B[0m│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m3\u001B[0m\u001B[2m \u001B[0m│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m4\u001B[0m\u001B[2m \u001B[0m│ fc2     │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m5\u001B[0m\u001B[2m \u001B[0m│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m6\u001B[0m\u001B[2m \u001B[0m│ fc3     │ Linear      │    513 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m7\u001B[0m\u001B[2m \u001B[0m│ fc_skip │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m8\u001B[0m\u001B[2m \u001B[0m│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ r2      │ R2Score     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ fc2     │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ fc3     │ Linear      │    513 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>│ fc_skip │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mTrainable params\u001B[0m: 2.6 M                                                                                            \n",
       "\u001B[1mNon-trainable params\u001B[0m: 0                                                                                            \n",
       "\u001B[1mTotal params\u001B[0m: 2.6 M                                                                                                \n",
       "\u001B[1mTotal estimated model params size (MB)\u001B[0m: 10                                                                         \n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 10                                                                         \n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f540ed374144909a0b12da39b0c4c8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 2.514\n",
      "Epoch 0, global step 36: 'val_loss' reached 0.68258 (best 0.68258), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=00-val_loss=0.68.ckpt' as top 1\n",
      "Metric train_loss improved by 1.811 >= min_delta = 0.0. New best score: 0.704\n",
      "Epoch 1, global step 72: 'val_loss' reached 0.57542 (best 0.57542), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=01-val_loss=0.58.ckpt' as top 1\n",
      "Metric train_loss improved by 0.106 >= min_delta = 0.0. New best score: 0.597\n",
      "Epoch 2, global step 108: 'val_loss' reached 0.50991 (best 0.50991), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=02-val_loss=0.51.ckpt' as top 1\n",
      "Metric train_loss improved by 0.051 >= min_delta = 0.0. New best score: 0.546\n",
      "Epoch 3, global step 144: 'val_loss' reached 0.48509 (best 0.48509), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=03-val_loss=0.49.ckpt' as top 1\n",
      "Metric train_loss improved by 0.043 >= min_delta = 0.0. New best score: 0.503\n",
      "Epoch 4, global step 180: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.026 >= min_delta = 0.0. New best score: 0.477\n",
      "Epoch 5, global step 216: 'val_loss' reached 0.45249 (best 0.45249), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=05-val_loss=0.45.ckpt' as top 1\n",
      "Metric train_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.458\n",
      "Epoch 6, global step 252: 'val_loss' reached 0.44038 (best 0.44038), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=06-val_loss=0.44.ckpt' as top 1\n",
      "Metric train_loss improved by 0.028 >= min_delta = 0.0. New best score: 0.430\n",
      "Epoch 7, global step 288: 'val_loss' reached 0.41884 (best 0.41884), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=07-val_loss=0.42.ckpt' as top 1\n",
      "Metric train_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.408\n",
      "Epoch 8, global step 324: 'val_loss' reached 0.41127 (best 0.41127), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=08-val_loss=0.41.ckpt' as top 1\n",
      "Metric train_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.398\n",
      "Epoch 9, global step 360: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.390\n",
      "Epoch 10, global step 396: 'val_loss' reached 0.39897 (best 0.39897), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=10-val_loss=0.40.ckpt' as top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.384\n",
      "Epoch 11, global step 432: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.360\n",
      "Epoch 12, global step 468: 'val_loss' reached 0.39395 (best 0.39395), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=12-val_loss=0.39.ckpt' as top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.351\n",
      "Epoch 13, global step 504: 'val_loss' reached 0.37905 (best 0.37905), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=13-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.344\n",
      "Epoch 14, global step 540: 'val_loss' reached 0.37886 (best 0.37886), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=14-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.334\n",
      "Epoch 15, global step 576: 'val_loss' reached 0.37568 (best 0.37568), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=15-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.327\n",
      "Epoch 16, global step 612: 'val_loss' was not in top 1\n",
      "Epoch 17, global step 648: 'val_loss' reached 0.37077 (best 0.37077), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=17-val_loss=0.37.ckpt' as top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.318\n",
      "Epoch 18, global step 684: 'val_loss' reached 0.36469 (best 0.36469), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=18-val_loss=0.36.ckpt' as top 1\n",
      "Metric train_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.307\n",
      "Epoch 19, global step 720: 'val_loss' reached 0.36071 (best 0.36071), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=19-val_loss=0.36.ckpt' as top 1\n",
      "Epoch 20, global step 756: 'val_loss' reached 0.35778 (best 0.35778), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=20-val_loss=0.36.ckpt' as top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.298\n",
      "Epoch 21, global step 792: 'val_loss' reached 0.35300 (best 0.35300), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=21-val_loss=0.35.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.296\n",
      "Epoch 22, global step 828: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.296\n",
      "Epoch 23, global step 864: 'val_loss' reached 0.34617 (best 0.34617), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=23-val_loss=0.35.ckpt' as top 1\n",
      "Metric train_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.283\n",
      "Epoch 24, global step 900: 'val_loss' reached 0.33778 (best 0.33778), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=24-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.280\n",
      "Epoch 25, global step 936: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.279\n",
      "Epoch 26, global step 972: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.273\n",
      "Epoch 27, global step 1008: 'val_loss' reached 0.33681 (best 0.33681), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=27-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.271\n",
      "Epoch 28, global step 1044: 'val_loss' reached 0.32211 (best 0.32211), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=28-val_loss=0.32.ckpt' as top 1\n",
      "Metric train_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.261\n",
      "Epoch 29, global step 1080: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.260\n",
      "Epoch 30, global step 1116: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.260\n",
      "Epoch 31, global step 1152: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.260\n",
      "Epoch 32, global step 1188: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.255\n",
      "Epoch 33, global step 1224: 'val_loss' reached 0.32029 (best 0.32029), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=33-val_loss=0.32.ckpt' as top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.250\n",
      "Epoch 34, global step 1260: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.249\n",
      "Epoch 35, global step 1296: 'val_loss' reached 0.31663 (best 0.31663), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=35-val_loss=0.32.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.246\n",
      "Epoch 36, global step 1332: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.246\n",
      "Epoch 37, global step 1368: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.241\n",
      "Epoch 38, global step 1404: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.236\n",
      "Epoch 39, global step 1440: 'val_loss' reached 0.31633 (best 0.31633), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=39-val_loss=0.32.ckpt' as top 1\n",
      "Epoch 40, global step 1476: 'val_loss' reached 0.31021 (best 0.31021), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=40-val_loss=0.31.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.236\n",
      "Epoch 41, global step 1512: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.231\n",
      "Epoch 42, global step 1548: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.227\n",
      "Epoch 43, global step 1584: 'val_loss' was not in top 1\n",
      "Epoch 44, global step 1620: 'val_loss' was not in top 1\n",
      "Epoch 45, global step 1656: 'val_loss' was not in top 1\n",
      "Epoch 46, global step 1692: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.222\n",
      "Epoch 47, global step 1728: 'val_loss' reached 0.30580 (best 0.30580), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=47-val_loss=0.31.ckpt' as top 1\n",
      "Epoch 48, global step 1764: 'val_loss' reached 0.30166 (best 0.30166), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=48-val_loss=0.30.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.220\n",
      "Epoch 49, global step 1800: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.218\n",
      "Epoch 50, global step 1836: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.213\n",
      "Epoch 51, global step 1872: 'val_loss' was not in top 1\n",
      "Epoch 52, global step 1908: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.213\n",
      "Epoch 53, global step 1944: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.209\n",
      "Epoch 54, global step 1980: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.207\n",
      "Epoch 55, global step 2016: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.206\n",
      "Epoch 56, global step 2052: 'val_loss' reached 0.29983 (best 0.29983), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=56-val_loss=0.30.ckpt' as top 1\n",
      "Epoch 57, global step 2088: 'val_loss' was not in top 1\n",
      "Epoch 58, global step 2124: 'val_loss' reached 0.29578 (best 0.29578), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=58-val_loss=0.30.ckpt' as top 1\n",
      "Epoch 59, global step 2160: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.206\n",
      "Epoch 60, global step 2196: 'val_loss' was not in top 1\n",
      "Epoch 61, global step 2232: 'val_loss' was not in top 1\n",
      "Epoch 62, global step 2268: 'val_loss' was not in top 1\n",
      "Epoch 63, global step 2304: 'val_loss' was not in top 1\n",
      "Epoch 64, global step 2340: 'val_loss' was not in top 1\n",
      "Epoch 65, global step 2376: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.203\n",
      "Epoch 66, global step 2412: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.194\n",
      "Epoch 67, global step 2448: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.193\n",
      "Epoch 68, global step 2484: 'val_loss' was not in top 1\n",
      "Epoch 69, global step 2520: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.180\n",
      "Epoch 70, global step 2556: 'val_loss' reached 0.28265 (best 0.28265), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=70-val_loss=0.28.ckpt' as top 1\n",
      "Metric train_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.168\n",
      "Epoch 71, global step 2592: 'val_loss' reached 0.27947 (best 0.27947), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=71-val_loss=0.28.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.166\n",
      "Epoch 72, global step 2628: 'val_loss' reached 0.27737 (best 0.27737), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=72-val_loss=0.28.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.164\n",
      "Epoch 73, global step 2664: 'val_loss' reached 0.27632 (best 0.27632), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=73-val_loss=0.28.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.162\n",
      "Epoch 74, global step 2700: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.156\n",
      "Epoch 75, global step 2736: 'val_loss' reached 0.27488 (best 0.27488), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=75-val_loss=0.27.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.154\n",
      "Epoch 76, global step 2772: 'val_loss' reached 0.27424 (best 0.27424), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=76-val_loss=0.27.ckpt' as top 1\n",
      "Epoch 77, global step 2808: 'val_loss' was not in top 1\n",
      "Epoch 78, global step 2844: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.151\n",
      "Epoch 79, global step 2880: 'val_loss' was not in top 1\n",
      "Epoch 80, global step 2916: 'val_loss' reached 0.27336 (best 0.27336), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=80-val_loss=0.27.ckpt' as top 1\n",
      "Epoch 81, global step 2952: 'val_loss' reached 0.27259 (best 0.27259), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=81-val_loss=0.27.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.150\n",
      "Epoch 82, global step 2988: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.148\n",
      "Epoch 83, global step 3024: 'val_loss' reached 0.27237 (best 0.27237), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=83-val_loss=0.27.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.146\n",
      "Epoch 84, global step 3060: 'val_loss' reached 0.27236 (best 0.27236), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=84-val_loss=0.27.ckpt' as top 1\n",
      "Epoch 85, global step 3096: 'val_loss' was not in top 1\n",
      "Epoch 86, global step 3132: 'val_loss' reached 0.27201 (best 0.27201), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=86-val_loss=0.27.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.146\n",
      "Epoch 87, global step 3168: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.144\n",
      "Epoch 88, global step 3204: 'val_loss' was not in top 1\n",
      "Epoch 89, global step 3240: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.142\n",
      "Epoch 90, global step 3276: 'val_loss' reached 0.27163 (best 0.27163), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=90-val_loss=0.27.ckpt' as top 1\n",
      "Epoch 91, global step 3312: 'val_loss' was not in top 1\n",
      "Epoch 92, global step 3348: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.141\n",
      "Epoch 93, global step 3384: 'val_loss' was not in top 1\n",
      "Epoch 94, global step 3420: 'val_loss' was not in top 1\n",
      "Epoch 95, global step 3456: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.140\n",
      "Epoch 96, global step 3492: 'val_loss' reached 0.27059 (best 0.27059), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=96-val_loss=0.27.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.139\n",
      "Epoch 97, global step 3528: 'val_loss' was not in top 1\n",
      "Epoch 98, global step 3564: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.139\n",
      "Epoch 99, global step 3600: 'val_loss' was not in top 1\n",
      "Epoch 100, global step 3636: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.135\n",
      "Epoch 101, global step 3672: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.135\n",
      "Epoch 102, global step 3708: 'val_loss' was not in top 1\n",
      "Epoch 103, global step 3744: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.134\n",
      "Epoch 104, global step 3780: 'val_loss' was not in top 1\n",
      "Epoch 105, global step 3816: 'val_loss' reached 0.26988 (best 0.26988), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=105-val_loss=0.27.ckpt' as top 1\n",
      "Epoch 106, global step 3852: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.133\n",
      "Epoch 107, global step 3888: 'val_loss' was not in top 1\n",
      "Epoch 108, global step 3924: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.132\n",
      "Epoch 109, global step 3960: 'val_loss' was not in top 1\n",
      "Epoch 110, global step 3996: 'val_loss' reached 0.26957 (best 0.26957), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\3\\\\epoch=110-val_loss=0.27.ckpt' as top 1\n",
      "Epoch 111, global step 4032: 'val_loss' was not in top 1\n",
      "Epoch 112, global step 4068: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.131\n",
      "Epoch 113, global step 4104: 'val_loss' was not in top 1\n",
      "Epoch 114, global step 4140: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.130\n",
      "Epoch 115, global step 4176: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.128\n",
      "Epoch 116, global step 4212: 'val_loss' was not in top 1\n",
      "Epoch 117, global step 4248: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.128\n",
      "Epoch 118, global step 4284: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.128\n",
      "Epoch 119, global step 4320: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.128\n",
      "Epoch 120, global step 4356: 'val_loss' was not in top 1\n",
      "Epoch 121, global step 4392: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.125\n",
      "Epoch 122, global step 4428: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.125\n",
      "Epoch 123, global step 4464: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.123\n",
      "Epoch 124, global step 4500: 'val_loss' was not in top 1\n",
      "Epoch 125, global step 4536: 'val_loss' was not in top 1\n",
      "Epoch 126, global step 4572: 'val_loss' was not in top 1\n",
      "Epoch 127, global step 4608: 'val_loss' was not in top 1\n",
      "Epoch 128, global step 4644: 'val_loss' was not in top 1\n",
      "Epoch 129, global step 4680: 'val_loss' was not in top 1\n",
      "Epoch 130, global step 4716: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.123\n",
      "Epoch 131, global step 4752: 'val_loss' was not in top 1\n",
      "Epoch 132, global step 4788: 'val_loss' was not in top 1\n",
      "Epoch 133, global step 4824: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.122\n",
      "Epoch 134, global step 4860: 'val_loss' was not in top 1\n",
      "Epoch 135, global step 4896: 'val_loss' was not in top 1\n",
      "Epoch 136, global step 4932: 'val_loss' was not in top 1\n",
      "Epoch 137, global step 4968: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.121\n",
      "Epoch 138, global step 5004: 'val_loss' was not in top 1\n",
      "Epoch 139, global step 5040: 'val_loss' was not in top 1\n",
      "Epoch 140, global step 5076: 'val_loss' was not in top 1\n",
      "Epoch 141, global step 5112: 'val_loss' was not in top 1\n",
      "Epoch 142, global step 5148: 'val_loss' was not in top 1\n",
      "Epoch 143, global step 5184: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.119\n",
      "Epoch 144, global step 5220: 'val_loss' was not in top 1\n",
      "Epoch 145, global step 5256: 'val_loss' was not in top 1\n",
      "Epoch 146, global step 5292: 'val_loss' was not in top 1\n",
      "Epoch 147, global step 5328: 'val_loss' was not in top 1\n",
      "Epoch 148, global step 5364: 'val_loss' was not in top 1\n",
      "Epoch 149, global step 5400: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aabb1df64fcb4c5598e51dff2a672dba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m     Validate metric     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        val_loss         \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.2706453502178192    \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36mvalidation_epoch_average \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.2702138423919678    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2706453502178192     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> validation_epoch_average  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2702138423919678     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f0e493350f1427ba4aff7d1509bdde5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_loss        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.2964266538619995    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2964266538619995     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 4, target_col 1507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: D:\\ds\\sync\\gdrive\\work\\gdrive-workspaces\\git\\nn_catalyst//checkpoints/stn_2_r1/lightning_logs\\4\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mName   \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mType       \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mParams\u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mMode \u001B[0m\u001B[1;35m \u001B[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001B[2m \u001B[0m\u001B[2m0\u001B[0m\u001B[2m \u001B[0m│ r2      │ R2Score     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m1\u001B[0m\u001B[2m \u001B[0m│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m2\u001B[0m\u001B[2m \u001B[0m│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m3\u001B[0m\u001B[2m \u001B[0m│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m4\u001B[0m\u001B[2m \u001B[0m│ fc2     │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m5\u001B[0m\u001B[2m \u001B[0m│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m6\u001B[0m\u001B[2m \u001B[0m│ fc3     │ Linear      │    513 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m7\u001B[0m\u001B[2m \u001B[0m│ fc_skip │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m8\u001B[0m\u001B[2m \u001B[0m│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ r2      │ R2Score     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ fc2     │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ fc3     │ Linear      │    513 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>│ fc_skip │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mTrainable params\u001B[0m: 2.6 M                                                                                            \n",
       "\u001B[1mNon-trainable params\u001B[0m: 0                                                                                            \n",
       "\u001B[1mTotal params\u001B[0m: 2.6 M                                                                                                \n",
       "\u001B[1mTotal estimated model params size (MB)\u001B[0m: 10                                                                         \n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 10                                                                         \n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d004abe0682f4ee2ad5cb1e0009322ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 2.073\n",
      "Epoch 0, global step 36: 'val_loss' reached 0.64559 (best 0.64559), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=00-val_loss=0.65.ckpt' as top 1\n",
      "Metric train_loss improved by 1.394 >= min_delta = 0.0. New best score: 0.679\n",
      "Epoch 1, global step 72: 'val_loss' reached 0.53865 (best 0.53865), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=01-val_loss=0.54.ckpt' as top 1\n",
      "Metric train_loss improved by 0.067 >= min_delta = 0.0. New best score: 0.612\n",
      "Epoch 2, global step 108: 'val_loss' reached 0.52953 (best 0.52953), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=02-val_loss=0.53.ckpt' as top 1\n",
      "Metric train_loss improved by 0.044 >= min_delta = 0.0. New best score: 0.568\n",
      "Epoch 3, global step 144: 'val_loss' reached 0.50916 (best 0.50916), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=03-val_loss=0.51.ckpt' as top 1\n",
      "Metric train_loss improved by 0.029 >= min_delta = 0.0. New best score: 0.540\n",
      "Epoch 4, global step 180: 'val_loss' reached 0.48064 (best 0.48064), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=04-val_loss=0.48.ckpt' as top 1\n",
      "Metric train_loss improved by 0.021 >= min_delta = 0.0. New best score: 0.519\n",
      "Epoch 5, global step 216: 'val_loss' reached 0.47588 (best 0.47588), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=05-val_loss=0.48.ckpt' as top 1\n",
      "Metric train_loss improved by 0.027 >= min_delta = 0.0. New best score: 0.491\n",
      "Epoch 6, global step 252: 'val_loss' reached 0.46302 (best 0.46302), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=06-val_loss=0.46.ckpt' as top 1\n",
      "Metric train_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.467\n",
      "Epoch 7, global step 288: 'val_loss' reached 0.45762 (best 0.45762), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=07-val_loss=0.46.ckpt' as top 1\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.454\n",
      "Epoch 8, global step 324: 'val_loss' reached 0.44730 (best 0.44730), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=08-val_loss=0.45.ckpt' as top 1\n",
      "Metric train_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.439\n",
      "Epoch 9, global step 360: 'val_loss' reached 0.44384 (best 0.44384), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=09-val_loss=0.44.ckpt' as top 1\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.432\n",
      "Epoch 10, global step 396: 'val_loss' reached 0.43028 (best 0.43028), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=10-val_loss=0.43.ckpt' as top 1\n",
      "Metric train_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.421\n",
      "Epoch 11, global step 432: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.416\n",
      "Epoch 12, global step 468: 'val_loss' reached 0.42333 (best 0.42333), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=12-val_loss=0.42.ckpt' as top 1\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.403\n",
      "Epoch 13, global step 504: 'val_loss' reached 0.40739 (best 0.40739), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=13-val_loss=0.41.ckpt' as top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.397\n",
      "Epoch 14, global step 540: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.388\n",
      "Epoch 15, global step 576: 'val_loss' reached 0.40728 (best 0.40728), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=15-val_loss=0.41.ckpt' as top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.382\n",
      "Epoch 16, global step 612: 'val_loss' reached 0.39946 (best 0.39946), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=16-val_loss=0.40.ckpt' as top 1\n",
      "Metric train_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.367\n",
      "Epoch 17, global step 648: 'val_loss' reached 0.39874 (best 0.39874), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=17-val_loss=0.40.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.367\n",
      "Epoch 18, global step 684: 'val_loss' reached 0.39314 (best 0.39314), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=18-val_loss=0.39.ckpt' as top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.358\n",
      "Epoch 19, global step 720: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.355\n",
      "Epoch 20, global step 756: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.354\n",
      "Epoch 21, global step 792: 'val_loss' reached 0.38636 (best 0.38636), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=21-val_loss=0.39.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.350\n",
      "Epoch 22, global step 828: 'val_loss' reached 0.38333 (best 0.38333), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=22-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.337\n",
      "Epoch 23, global step 864: 'val_loss' reached 0.38176 (best 0.38176), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=23-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.333\n",
      "Epoch 24, global step 900: 'val_loss' reached 0.37483 (best 0.37483), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=24-val_loss=0.37.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.332\n",
      "Epoch 25, global step 936: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.327\n",
      "Epoch 26, global step 972: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.324\n",
      "Epoch 27, global step 1008: 'val_loss' reached 0.37317 (best 0.37317), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=27-val_loss=0.37.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.321\n",
      "Epoch 28, global step 1044: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.316\n",
      "Epoch 29, global step 1080: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.315\n",
      "Epoch 30, global step 1116: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.311\n",
      "Epoch 31, global step 1152: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.308\n",
      "Epoch 32, global step 1188: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.302\n",
      "Epoch 33, global step 1224: 'val_loss' reached 0.37040 (best 0.37040), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=33-val_loss=0.37.ckpt' as top 1\n",
      "Epoch 34, global step 1260: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.299\n",
      "Epoch 35, global step 1296: 'val_loss' reached 0.36050 (best 0.36050), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=35-val_loss=0.36.ckpt' as top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.294\n",
      "Epoch 36, global step 1332: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.291\n",
      "Epoch 37, global step 1368: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.289\n",
      "Epoch 38, global step 1404: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.288\n",
      "Epoch 39, global step 1440: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.283\n",
      "Epoch 40, global step 1476: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.278\n",
      "Epoch 41, global step 1512: 'val_loss' was not in top 1\n",
      "Epoch 42, global step 1548: 'val_loss' reached 0.35811 (best 0.35811), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=42-val_loss=0.36.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.275\n",
      "Epoch 43, global step 1584: 'val_loss' was not in top 1\n",
      "Epoch 44, global step 1620: 'val_loss' reached 0.34758 (best 0.34758), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=44-val_loss=0.35.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.271\n",
      "Epoch 45, global step 1656: 'val_loss' was not in top 1\n",
      "Epoch 46, global step 1692: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.270\n",
      "Epoch 47, global step 1728: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.264\n",
      "Epoch 48, global step 1764: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.258\n",
      "Epoch 49, global step 1800: 'val_loss' was not in top 1\n",
      "Epoch 50, global step 1836: 'val_loss' was not in top 1\n",
      "Epoch 51, global step 1872: 'val_loss' was not in top 1\n",
      "Epoch 52, global step 1908: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.255\n",
      "Epoch 53, global step 1944: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.253\n",
      "Epoch 54, global step 1980: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.249\n",
      "Epoch 55, global step 2016: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.235\n",
      "Epoch 56, global step 2052: 'val_loss' reached 0.33821 (best 0.33821), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=56-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.222\n",
      "Epoch 57, global step 2088: 'val_loss' reached 0.33527 (best 0.33527), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=57-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.217\n",
      "Epoch 58, global step 2124: 'val_loss' reached 0.33515 (best 0.33515), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=58-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.213\n",
      "Epoch 59, global step 2160: 'val_loss' reached 0.33457 (best 0.33457), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=59-val_loss=0.33.ckpt' as top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.210\n",
      "Epoch 60, global step 2196: 'val_loss' was not in top 1\n",
      "Epoch 61, global step 2232: 'val_loss' reached 0.33414 (best 0.33414), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=61-val_loss=0.33.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.206\n",
      "Epoch 62, global step 2268: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.204\n",
      "Epoch 63, global step 2304: 'val_loss' reached 0.33378 (best 0.33378), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=63-val_loss=0.33.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.203\n",
      "Epoch 64, global step 2340: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.199\n",
      "Epoch 65, global step 2376: 'val_loss' reached 0.33169 (best 0.33169), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\4\\\\epoch=65-val_loss=0.33.ckpt' as top 1\n",
      "Epoch 66, global step 2412: 'val_loss' was not in top 1\n",
      "Epoch 67, global step 2448: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.198\n",
      "Epoch 68, global step 2484: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.197\n",
      "Epoch 69, global step 2520: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.195\n",
      "Epoch 70, global step 2556: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.194\n",
      "Epoch 71, global step 2592: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.193\n",
      "Epoch 72, global step 2628: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.189\n",
      "Epoch 73, global step 2664: 'val_loss' was not in top 1\n",
      "Epoch 74, global step 2700: 'val_loss' was not in top 1\n",
      "Epoch 75, global step 2736: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.188\n",
      "Epoch 76, global step 2772: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.188\n",
      "Epoch 77, global step 2808: 'val_loss' was not in top 1\n",
      "Epoch 78, global step 2844: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.185\n",
      "Epoch 79, global step 2880: 'val_loss' was not in top 1\n",
      "Epoch 80, global step 2916: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.183\n",
      "Epoch 81, global step 2952: 'val_loss' was not in top 1\n",
      "Epoch 82, global step 2988: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.183\n",
      "Epoch 83, global step 3024: 'val_loss' was not in top 1\n",
      "Epoch 84, global step 3060: 'val_loss' was not in top 1\n",
      "Epoch 85, global step 3096: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.183\n",
      "Epoch 86, global step 3132: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.182\n",
      "Epoch 87, global step 3168: 'val_loss' was not in top 1\n",
      "Epoch 88, global step 3204: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.181\n",
      "Epoch 89, global step 3240: 'val_loss' was not in top 1\n",
      "Epoch 90, global step 3276: 'val_loss' was not in top 1\n",
      "Epoch 91, global step 3312: 'val_loss' was not in top 1\n",
      "Epoch 92, global step 3348: 'val_loss' was not in top 1\n",
      "Epoch 93, global step 3384: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.181\n",
      "Epoch 94, global step 3420: 'val_loss' was not in top 1\n",
      "Epoch 95, global step 3456: 'val_loss' was not in top 1\n",
      "Epoch 96, global step 3492: 'val_loss' was not in top 1\n",
      "Epoch 97, global step 3528: 'val_loss' was not in top 1\n",
      "Epoch 98, global step 3564: 'val_loss' was not in top 1\n",
      "Epoch 99, global step 3600: 'val_loss' was not in top 1\n",
      "Epoch 100, global step 3636: 'val_loss' was not in top 1\n",
      "Epoch 101, global step 3672: 'val_loss' was not in top 1\n",
      "Epoch 102, global step 3708: 'val_loss' was not in top 1\n",
      "Epoch 103, global step 3744: 'val_loss' was not in top 1\n",
      "Monitored metric train_loss did not improve in the last 10 records. Best score: 0.181. Signaling Trainer to stop.\n",
      "Epoch 104, global step 3780: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bab99b2df43d41bf8781971f42fcce74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m     Validate metric     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        val_loss         \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.33299916982650757   \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36mvalidation_epoch_average \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m    0.332925021648407    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33299916982650757    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> validation_epoch_average  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.332925021648407     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3315ff1a73c64ca7aa62e04d1dc24558"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_loss        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.3769153356552124    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3769153356552124     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 5, target_col 1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: D:\\ds\\sync\\gdrive\\work\\gdrive-workspaces\\git\\nn_catalyst//checkpoints/stn_2_r1/lightning_logs\\5\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mName   \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mType       \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mParams\u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mMode \u001B[0m\u001B[1;35m \u001B[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001B[2m \u001B[0m\u001B[2m0\u001B[0m\u001B[2m \u001B[0m│ r2      │ R2Score     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m1\u001B[0m\u001B[2m \u001B[0m│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m2\u001B[0m\u001B[2m \u001B[0m│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m3\u001B[0m\u001B[2m \u001B[0m│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m4\u001B[0m\u001B[2m \u001B[0m│ fc2     │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m5\u001B[0m\u001B[2m \u001B[0m│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m6\u001B[0m\u001B[2m \u001B[0m│ fc3     │ Linear      │    513 │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m7\u001B[0m\u001B[2m \u001B[0m│ fc_skip │ Linear      │  524 K │ train │\n",
       "│\u001B[2m \u001B[0m\u001B[2m8\u001B[0m\u001B[2m \u001B[0m│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ r2      │ R2Score     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ loss_fn │ MSELoss     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ fc1     │ Linear      │  1.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ bn1     │ BatchNorm1d │  2.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ fc2     │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ bn2     │ BatchNorm1d │  1.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ fc3     │ Linear      │    513 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>│ fc_skip │ Linear      │  524 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>│ dropout │ Dropout     │      0 │ train │\n",
       "└───┴─────────┴─────────────┴────────┴───────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mTrainable params\u001B[0m: 2.6 M                                                                                            \n",
       "\u001B[1mNon-trainable params\u001B[0m: 0                                                                                            \n",
       "\u001B[1mTotal params\u001B[0m: 2.6 M                                                                                                \n",
       "\u001B[1mTotal estimated model params size (MB)\u001B[0m: 10                                                                         \n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 10                                                                         \n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a7b1f3d54b1459f9dbd239b4c2310dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the\n",
       "`num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:4\n",
       "24: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of \n",
       "the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 1.881\n",
      "Epoch 0, global step 36: 'val_loss' reached 0.68040 (best 0.68040), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=00-val_loss=0.68.ckpt' as top 1\n",
      "Metric train_loss improved by 1.205 >= min_delta = 0.0. New best score: 0.677\n",
      "Epoch 1, global step 72: 'val_loss' reached 0.58298 (best 0.58298), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=01-val_loss=0.58.ckpt' as top 1\n",
      "Metric train_loss improved by 0.078 >= min_delta = 0.0. New best score: 0.599\n",
      "Epoch 2, global step 108: 'val_loss' reached 0.52683 (best 0.52683), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=02-val_loss=0.53.ckpt' as top 1\n",
      "Metric train_loss improved by 0.060 >= min_delta = 0.0. New best score: 0.540\n",
      "Epoch 3, global step 144: 'val_loss' reached 0.48329 (best 0.48329), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=03-val_loss=0.48.ckpt' as top 1\n",
      "Metric train_loss improved by 0.041 >= min_delta = 0.0. New best score: 0.499\n",
      "Epoch 4, global step 180: 'val_loss' reached 0.46553 (best 0.46553), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=04-val_loss=0.47.ckpt' as top 1\n",
      "Metric train_loss improved by 0.039 >= min_delta = 0.0. New best score: 0.459\n",
      "Epoch 5, global step 216: 'val_loss' reached 0.45216 (best 0.45216), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=05-val_loss=0.45.ckpt' as top 1\n",
      "Metric train_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.443\n",
      "Epoch 6, global step 252: 'val_loss' reached 0.44031 (best 0.44031), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=06-val_loss=0.44.ckpt' as top 1\n",
      "Metric train_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.426\n",
      "Epoch 7, global step 288: 'val_loss' reached 0.43289 (best 0.43289), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=07-val_loss=0.43.ckpt' as top 1\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.414\n",
      "Epoch 8, global step 324: 'val_loss' reached 0.42247 (best 0.42247), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=08-val_loss=0.42.ckpt' as top 1\n",
      "Metric train_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.396\n",
      "Epoch 9, global step 360: 'val_loss' reached 0.41018 (best 0.41018), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=09-val_loss=0.41.ckpt' as top 1\n",
      "Metric train_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.383\n",
      "Epoch 10, global step 396: 'val_loss' reached 0.40949 (best 0.40949), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=10-val_loss=0.41.ckpt' as top 1\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.375\n",
      "Epoch 11, global step 432: 'val_loss' reached 0.40005 (best 0.40005), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=11-val_loss=0.40.ckpt' as top 1\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.362\n",
      "Epoch 12, global step 468: 'val_loss' reached 0.39945 (best 0.39945), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=12-val_loss=0.40.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.360\n",
      "Epoch 13, global step 504: 'val_loss' reached 0.39299 (best 0.39299), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=13-val_loss=0.39.ckpt' as top 1\n",
      "Metric train_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.349\n",
      "Epoch 14, global step 540: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.345\n",
      "Epoch 15, global step 576: 'val_loss' reached 0.38998 (best 0.38998), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=15-val_loss=0.39.ckpt' as top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.339\n",
      "Epoch 16, global step 612: 'val_loss' reached 0.38417 (best 0.38417), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=16-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.338\n",
      "Epoch 17, global step 648: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.330\n",
      "Epoch 18, global step 684: 'val_loss' reached 0.38034 (best 0.38034), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=18-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.328\n",
      "Epoch 19, global step 720: 'val_loss' reached 0.37628 (best 0.37628), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=19-val_loss=0.38.ckpt' as top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.322\n",
      "Epoch 20, global step 756: 'val_loss' reached 0.37324 (best 0.37324), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=20-val_loss=0.37.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.318\n",
      "Epoch 21, global step 792: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.309\n",
      "Epoch 22, global step 828: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.308\n",
      "Epoch 23, global step 864: 'val_loss' reached 0.37224 (best 0.37224), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=23-val_loss=0.37.ckpt' as top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.305\n",
      "Epoch 24, global step 900: 'val_loss' reached 0.36661 (best 0.36661), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=24-val_loss=0.37.ckpt' as top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.302\n",
      "Epoch 25, global step 936: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.298\n",
      "Epoch 26, global step 972: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.295\n",
      "Epoch 27, global step 1008: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.294\n",
      "Epoch 28, global step 1044: 'val_loss' reached 0.35911 (best 0.35911), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=28-val_loss=0.36.ckpt' as top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.289\n",
      "Epoch 29, global step 1080: 'val_loss' was not in top 1\n",
      "Epoch 30, global step 1116: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.283\n",
      "Epoch 31, global step 1152: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.282\n",
      "Epoch 32, global step 1188: 'val_loss' reached 0.35631 (best 0.35631), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=32-val_loss=0.36.ckpt' as top 1\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.276\n",
      "Epoch 33, global step 1224: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.276\n",
      "Epoch 34, global step 1260: 'val_loss' reached 0.35613 (best 0.35613), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=34-val_loss=0.36.ckpt' as top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.271\n",
      "Epoch 35, global step 1296: 'val_loss' reached 0.35591 (best 0.35591), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=35-val_loss=0.36.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.271\n",
      "Epoch 36, global step 1332: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.268\n",
      "Epoch 37, global step 1368: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.267\n",
      "Epoch 38, global step 1404: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.263\n",
      "Epoch 39, global step 1440: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.259\n",
      "Epoch 40, global step 1476: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.258\n",
      "Epoch 41, global step 1512: 'val_loss' was not in top 1\n",
      "Epoch 42, global step 1548: 'val_loss' was not in top 1\n",
      "Epoch 43, global step 1584: 'val_loss' reached 0.35416 (best 0.35416), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=43-val_loss=0.35.ckpt' as top 1\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.250\n",
      "Epoch 44, global step 1620: 'val_loss' was not in top 1\n",
      "Epoch 45, global step 1656: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.246\n",
      "Epoch 46, global step 1692: 'val_loss' was not in top 1\n",
      "Epoch 47, global step 1728: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.243\n",
      "Epoch 48, global step 1764: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.239\n",
      "Epoch 49, global step 1800: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.239\n",
      "Epoch 50, global step 1836: 'val_loss' was not in top 1\n",
      "Epoch 51, global step 1872: 'val_loss' was not in top 1\n",
      "Epoch 52, global step 1908: 'val_loss' reached 0.35395 (best 0.35395), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=52-val_loss=0.35.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.238\n",
      "Epoch 53, global step 1944: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.236\n",
      "Epoch 54, global step 1980: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.220\n",
      "Epoch 55, global step 2016: 'val_loss' reached 0.34291 (best 0.34291), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=55-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.206\n",
      "Epoch 56, global step 2052: 'val_loss' reached 0.34048 (best 0.34048), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=56-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.203\n",
      "Epoch 57, global step 2088: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.197\n",
      "Epoch 58, global step 2124: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.196\n",
      "Epoch 59, global step 2160: 'val_loss' reached 0.34028 (best 0.34028), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=59-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.195\n",
      "Epoch 60, global step 2196: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.192\n",
      "Epoch 61, global step 2232: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.191\n",
      "Epoch 62, global step 2268: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.189\n",
      "Epoch 63, global step 2304: 'val_loss' reached 0.33924 (best 0.33924), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=63-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.185\n",
      "Epoch 64, global step 2340: 'val_loss' was not in top 1\n",
      "Epoch 65, global step 2376: 'val_loss' was not in top 1\n",
      "Epoch 66, global step 2412: 'val_loss' reached 0.33901 (best 0.33901), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=66-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.184\n",
      "Epoch 67, global step 2448: 'val_loss' was not in top 1\n",
      "Epoch 68, global step 2484: 'val_loss' reached 0.33875 (best 0.33875), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=68-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.184\n",
      "Epoch 69, global step 2520: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.183\n",
      "Epoch 70, global step 2556: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.180\n",
      "Epoch 71, global step 2592: 'val_loss' was not in top 1\n",
      "Epoch 72, global step 2628: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.179\n",
      "Epoch 73, global step 2664: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.178\n",
      "Epoch 74, global step 2700: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.178\n",
      "Epoch 75, global step 2736: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.175\n",
      "Epoch 76, global step 2772: 'val_loss' was not in top 1\n",
      "Epoch 77, global step 2808: 'val_loss' was not in top 1\n",
      "Epoch 78, global step 2844: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.171\n",
      "Epoch 79, global step 2880: 'val_loss' was not in top 1\n",
      "Epoch 80, global step 2916: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.170\n",
      "Epoch 81, global step 2952: 'val_loss' reached 0.33853 (best 0.33853), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=81-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.168\n",
      "Epoch 82, global step 2988: 'val_loss' reached 0.33848 (best 0.33848), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=82-val_loss=0.34.ckpt' as top 1\n",
      "Epoch 83, global step 3024: 'val_loss' was not in top 1\n",
      "Epoch 84, global step 3060: 'val_loss' reached 0.33839 (best 0.33839), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=84-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.168\n",
      "Epoch 85, global step 3096: 'val_loss' reached 0.33823 (best 0.33823), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=85-val_loss=0.34.ckpt' as top 1\n",
      "Epoch 86, global step 3132: 'val_loss' reached 0.33804 (best 0.33804), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=86-val_loss=0.34.ckpt' as top 1\n",
      "Epoch 87, global step 3168: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.168\n",
      "Epoch 88, global step 3204: 'val_loss' reached 0.33803 (best 0.33803), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=88-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.167\n",
      "Epoch 89, global step 3240: 'val_loss' was not in top 1\n",
      "Epoch 90, global step 3276: 'val_loss' reached 0.33795 (best 0.33795), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=90-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.167\n",
      "Epoch 91, global step 3312: 'val_loss' reached 0.33786 (best 0.33786), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=91-val_loss=0.34.ckpt' as top 1\n",
      "Epoch 92, global step 3348: 'val_loss' reached 0.33784 (best 0.33784), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=92-val_loss=0.34.ckpt' as top 1\n",
      "Epoch 93, global step 3384: 'val_loss' was not in top 1\n",
      "Epoch 94, global step 3420: 'val_loss' was not in top 1\n",
      "Epoch 95, global step 3456: 'val_loss' was not in top 1\n",
      "Epoch 96, global step 3492: 'val_loss' reached 0.33780 (best 0.33780), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=96-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.166\n",
      "Epoch 97, global step 3528: 'val_loss' reached 0.33774 (best 0.33774), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=97-val_loss=0.34.ckpt' as top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.166\n",
      "Epoch 98, global step 3564: 'val_loss' reached 0.33773 (best 0.33773), saving model to 'D:\\\\ds\\\\sync\\\\gdrive\\\\work\\\\gdrive-workspaces\\\\git\\\\nn_catalyst\\\\checkpoints\\\\stn_2_r1\\\\5\\\\epoch=98-val_loss=0.34.ckpt' as top 1\n",
      "Epoch 99, global step 3600: 'val_loss' was not in top 1\n",
      "Epoch 100, global step 3636: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.166\n",
      "Epoch 101, global step 3672: 'val_loss' was not in top 1\n",
      "Epoch 102, global step 3708: 'val_loss' was not in top 1\n",
      "Epoch 103, global step 3744: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.165\n",
      "Epoch 104, global step 3780: 'val_loss' was not in top 1\n",
      "Epoch 105, global step 3816: 'val_loss' was not in top 1\n",
      "Epoch 106, global step 3852: 'val_loss' was not in top 1\n",
      "Epoch 107, global step 3888: 'val_loss' was not in top 1\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.165\n",
      "Epoch 108, global step 3924: 'val_loss' was not in top 1\n",
      "Epoch 109, global step 3960: 'val_loss' was not in top 1\n",
      "Epoch 110, global step 3996: 'val_loss' was not in top 1\n",
      "Epoch 111, global step 4032: 'val_loss' was not in top 1\n",
      "Epoch 112, global step 4068: 'val_loss' was not in top 1\n",
      "Epoch 113, global step 4104: 'val_loss' was not in top 1\n",
      "Epoch 114, global step 4140: 'val_loss' was not in top 1\n",
      "Epoch 115, global step 4176: 'val_loss' was not in top 1\n",
      "Epoch 116, global step 4212: 'val_loss' was not in top 1\n",
      "Epoch 117, global step 4248: 'val_loss' was not in top 1\n",
      "Monitored metric train_loss did not improve in the last 10 records. Best score: 0.165. Signaling Trainer to stop.\n",
      "Epoch 118, global step 4284: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36f70480797b4b3d8e4bfb4210eef009"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m     Validate metric     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        val_loss         \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.3380034267902374    \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36mvalidation_epoch_average \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.33751100301742554   \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3380034267902374     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> validation_epoch_average  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.33751100301742554    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa7e8fdfda8e4213b7232cf43e96c07b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m        test_loss        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m   0.3127690851688385    \u001B[0m\u001B[35m \u001B[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3127690851688385     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "f9ceeceac39b7c6d",
    "ExecuteTime": {
     "end_time": "2024-11-12T01:22:04.843302Z",
     "start_time": "2024-11-12T01:22:04.837790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchmetrics import R2Score\n",
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "def r2scoreAndMSE(model, dataloader):\n",
    "    r2_score_metric = R2Score()\n",
    "    mse = MeanSquaredError()\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        predictions = model(data)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        r2_score_metric.update(predictions, target)\n",
    "        mse.update(predictions, target)\n",
    "    return r2_score_metric.compute().detach().item(), mse.compute().detach().item()"
   ],
   "id": "f9ceeceac39b7c6d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T01:31:38.080721Z",
     "start_time": "2024-11-12T01:31:36.374675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "\n",
    "def measure_all_targets(xy_data, total_targets):\n",
    "    total_cols = xy_data.shape[1]\n",
    "    for target_num in range(1, total_targets+1):\n",
    "        target_col_start = total_cols - (total_targets - target_num)\n",
    "        print(f'Target {target_num}, target_col {target_col_start}')\n",
    "        xy_data = torch.from_numpy(xy_orig[:,:target_col_start]).float()  # size [n_samples, n_features]\n",
    "        dm = prepare_data_module(xy_data)\n",
    "        if DEBUG == True:\n",
    "            print(f\"Train set size: {len(dm.train_ds),dm.train_ds.dataset.x.shape[1]}\")\n",
    "            print(f\"Test set size: {len(dm.test_ds)}, Valid set size: {len(dm.val_ds)}\")\n",
    "\n",
    "        checkpoint_path=resolve_path_gdrive(f'{CHECKPOINTS_FOLDER}/{target_num}')\n",
    "        pathlist = Path(checkpoint_path).glob('**/*.ckpt')\n",
    "        for path in pathlist:\n",
    "            # because path is object not string\n",
    "            model = SingleTargetNet.load_from_checkpoint(str(path))\n",
    "            model.eval()\n",
    "            model.cpu()\n",
    "            # add row to resultsDF\n",
    "            train_r2, train_mse = r2scoreAndMSE(model, dm.train_dataloader())\n",
    "            val_r2, val_mse = r2scoreAndMSE(model, dm.val_dataloader())\n",
    "            test_r2, test_mse = r2scoreAndMSE(model, dm.test_dataloader())\n",
    "\n",
    "            results.append([target, os.path.basename(path), train_r2, train_mse, val_r2, val_mse, test_r2, test_mse])\n",
    "\n",
    "results = []        \n",
    "if __name__ == \"__main__\":\n",
    "    measure_all_targets(xy_orig, total_targets=5)"
   ],
   "id": "9dad6061d6b9e738",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target 1, target_col 1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "d:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\pytorch_lightning\\utilities\\migration\\utils.py:56: The loaded checkpoint was produced with Lightning v2.4.0, which is newer than your current Lightning version: v2.3.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x1503 and 1479x1024)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 31\u001B[0m\n\u001B[0;32m     29\u001B[0m results \u001B[38;5;241m=\u001B[39m []        \n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 31\u001B[0m     \u001B[43mmeasure_all_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxy_orig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_targets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[12], line 23\u001B[0m, in \u001B[0;36mmeasure_all_targets\u001B[1;34m(xy_data, total_targets)\u001B[0m\n\u001B[0;32m     21\u001B[0m model\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# add row to resultsDF\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m train_r2, train_mse \u001B[38;5;241m=\u001B[39m \u001B[43mr2scoreAndMSE\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m val_r2, val_mse \u001B[38;5;241m=\u001B[39m r2scoreAndMSE(model, dm\u001B[38;5;241m.\u001B[39mval_dataloader())\n\u001B[0;32m     25\u001B[0m test_r2, test_mse \u001B[38;5;241m=\u001B[39m r2scoreAndMSE(model, dm\u001B[38;5;241m.\u001B[39mtest_dataloader())\n",
      "Cell \u001B[1;32mIn[9], line 8\u001B[0m, in \u001B[0;36mr2scoreAndMSE\u001B[1;34m(model, dataloader)\u001B[0m\n\u001B[0;32m      6\u001B[0m mse \u001B[38;5;241m=\u001B[39m MeanSquaredError()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (data, target) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[1;32m----> 8\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m#import pdb; pdb.set_trace()\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     r2_score_metric\u001B[38;5;241m.\u001B[39mupdate(predictions, target)\n",
      "File \u001B[1;32md:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32md:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 76\u001B[0m, in \u001B[0;36mSingleTargetNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 76\u001B[0m     x1 \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[0;32m     77\u001B[0m     x1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(x1)\n\u001B[0;32m     79\u001B[0m     x2 \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(x1)))\n",
      "File \u001B[1;32md:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32md:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32md:\\ds\\work\\utilities\\conda\\envs\\nn_310_2\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (512x1503 and 1479x1024)"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1\n",
      "Train set size: 20986, Test set size: 2623, Valid set size: 2624\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "results = []\n",
    "if __name__ == \"__main__\":\n",
    "    # do everything in a loop for all the targets\n",
    "    for target in range(1, ):\n",
    "        print(f\"Target: {target}\")\n",
    "        dm = CatalystDataModule(\n",
    "            data_dir=\"\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            target_num=target\n",
    "        )\n",
    "        dm.prepare_data()\n",
    "        dm.setup()\n",
    "        if DEBUG == True:\n",
    "            print(f\"Train set size: {len(dm.train_ds),dm.train_ds.dataset.x_data.shape[1]}\")\n",
    "            print(f\"Test set size: {len(dm.test_ds)}, Valid set size: {len(dm.val_ds)}\")\n",
    "\n",
    "        checkpoint_path=resolve_path_gdrive(f'{CHECKPOINTS_FOLDER}/{dm.target_num}')\n",
    "        pathlist = Path(checkpoint_path).glob('**/*.ckpt')\n",
    "        for path in pathlist:\n",
    "            # because path is object not string\n",
    "            model = SingleTargetNet.load_from_checkpoint(str(path))\n",
    "            model.eval()\n",
    "            model.cpu()\n",
    "            # add row to resultsDF\n",
    "            train_r2, train_mse = r2scoreAndMSE(model, dm.train_dataloader())\n",
    "            val_r2, val_mse = r2scoreAndMSE(model, dm.val_dataloader())\n",
    "            test_r2, test_mse = r2scoreAndMSE(model, dm.test_dataloader())\n",
    "\n",
    "            results.append([target, os.path.basename(path), train_r2, train_mse, val_r2, val_mse, test_r2, test_mse])\n"
   ],
   "id": "MEA9-WzTGPGL"
  },
  {
   "metadata": {
    "id": "3af373f6ab2cec1a",
    "outputId": "04ac3e88-cb99-4862-b47b-35cbc05c5355",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    }
   },
   "cell_type": "code",
   "source": [
    "resultsDFcolumns = [\"Target\", \"ModelFile\", \"Train R2\", \"Train MSE\", \"Val R2\", \"Val MSE\", \"Test R2\", \"Test MSE\"]\n",
    "resultsDF = pd.DataFrame(results, columns=resultsDFcolumns)\n",
    "resultsDF"
   ],
   "id": "3af373f6ab2cec1a",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Target                     ModelFile  Train R2  Train MSE    Val R2  \\\n",
       "0        1   epoch=56-val_loss=0.00.ckpt  0.998835   0.001165  0.998835   \n",
       "1        2   epoch=97-val_loss=0.00.ckpt  0.998941   0.001059  0.998941   \n",
       "2        3   epoch=69-val_loss=0.00.ckpt  0.998975   0.001025  0.998975   \n",
       "3        4   epoch=86-val_loss=0.00.ckpt  0.999022   0.000978  0.999022   \n",
       "4        5   epoch=91-val_loss=0.00.ckpt  0.999025   0.000975  0.999025   \n",
       "5        6   epoch=80-val_loss=0.00.ckpt  0.999070   0.000930  0.999070   \n",
       "6        7  epoch=148-val_loss=0.02.ckpt  0.983475   0.016525  0.983475   \n",
       "7        8  epoch=146-val_loss=0.02.ckpt  0.983833   0.016167  0.983833   \n",
       "8        9  epoch=144-val_loss=0.01.ckpt  0.987937   0.012063  0.987937   \n",
       "9       10   epoch=58-val_loss=0.03.ckpt  0.965896   0.034103  0.965896   \n",
       "10      11   epoch=51-val_loss=0.04.ckpt  0.963759   0.036241  0.963759   \n",
       "11      12  epoch=145-val_loss=0.02.ckpt  0.980018   0.019982  0.980018   \n",
       "12      13  epoch=112-val_loss=0.01.ckpt  0.986921   0.013079  0.986921   \n",
       "13      14   epoch=67-val_loss=0.03.ckpt  0.969523   0.030477  0.969523   \n",
       "14      15  epoch=142-val_loss=0.01.ckpt  0.992332   0.007668  0.992332   \n",
       "15      16  epoch=147-val_loss=0.02.ckpt  0.981387   0.018613  0.981387   \n",
       "16      17  epoch=148-val_loss=0.03.ckpt  0.971864   0.028136  0.971864   \n",
       "17      18  epoch=149-val_loss=0.03.ckpt  0.971640   0.028360  0.971640   \n",
       "18      19   epoch=71-val_loss=0.03.ckpt  0.972199   0.027801  0.972199   \n",
       "19      20  epoch=149-val_loss=0.04.ckpt  0.957198   0.042802  0.957198   \n",
       "20      21  epoch=146-val_loss=0.03.ckpt  0.968669   0.031331  0.968669   \n",
       "21      22  epoch=141-val_loss=0.01.ckpt  0.992863   0.007137  0.992863   \n",
       "22      23  epoch=148-val_loss=0.04.ckpt  0.962613   0.037387  0.962613   \n",
       "23      24  epoch=147-val_loss=0.03.ckpt  0.967102   0.032898  0.967102   \n",
       "24      25  epoch=149-val_loss=0.04.ckpt  0.960003   0.039997  0.960003   \n",
       "25      26  epoch=149-val_loss=0.07.ckpt  0.932378   0.067622  0.932378   \n",
       "26      27  epoch=148-val_loss=0.09.ckpt  0.914410   0.085590  0.914410   \n",
       "27      28  epoch=148-val_loss=0.11.ckpt  0.888208   0.111792  0.888208   \n",
       "28      29  epoch=147-val_loss=0.10.ckpt  0.902048   0.097952  0.902048   \n",
       "\n",
       "     Val MSE   Test R2  Test MSE  \n",
       "0   0.001165  0.998835  0.001165  \n",
       "1   0.001059  0.998941  0.001059  \n",
       "2   0.001025  0.998975  0.001025  \n",
       "3   0.000978  0.999022  0.000978  \n",
       "4   0.000975  0.999025  0.000975  \n",
       "5   0.000930  0.999070  0.000930  \n",
       "6   0.016525  0.983475  0.016525  \n",
       "7   0.016167  0.983833  0.016167  \n",
       "8   0.012063  0.987937  0.012063  \n",
       "9   0.034103  0.965896  0.034103  \n",
       "10  0.036241  0.963759  0.036241  \n",
       "11  0.019982  0.980018  0.019982  \n",
       "12  0.013079  0.986921  0.013079  \n",
       "13  0.030477  0.969523  0.030477  \n",
       "14  0.007668  0.992332  0.007668  \n",
       "15  0.018613  0.981387  0.018613  \n",
       "16  0.028136  0.971864  0.028136  \n",
       "17  0.028360  0.971640  0.028360  \n",
       "18  0.027801  0.972199  0.027801  \n",
       "19  0.042802  0.957198  0.042802  \n",
       "20  0.031331  0.968669  0.031331  \n",
       "21  0.007137  0.992863  0.007137  \n",
       "22  0.037387  0.962613  0.037387  \n",
       "23  0.032898  0.967102  0.032898  \n",
       "24  0.039997  0.960003  0.039997  \n",
       "25  0.067622  0.932378  0.067622  \n",
       "26  0.085590  0.914410  0.085590  \n",
       "27  0.111792  0.888208  0.111792  \n",
       "28  0.097952  0.902048  0.097952  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-bc068e4f-eb19-4640-846b-d5e5d96b1917\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>ModelFile</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Val R2</th>\n",
       "      <th>Val MSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>epoch=56-val_loss=0.00.ckpt</td>\n",
       "      <td>0.998835</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.998835</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.998835</td>\n",
       "      <td>0.001165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>epoch=97-val_loss=0.00.ckpt</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>epoch=69-val_loss=0.00.ckpt</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.998975</td>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>epoch=86-val_loss=0.00.ckpt</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>epoch=91-val_loss=0.00.ckpt</td>\n",
       "      <td>0.999025</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.999025</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.999025</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>epoch=80-val_loss=0.00.ckpt</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.999070</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>epoch=148-val_loss=0.02.ckpt</td>\n",
       "      <td>0.983475</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.983475</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.983475</td>\n",
       "      <td>0.016525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>epoch=146-val_loss=0.02.ckpt</td>\n",
       "      <td>0.983833</td>\n",
       "      <td>0.016167</td>\n",
       "      <td>0.983833</td>\n",
       "      <td>0.016167</td>\n",
       "      <td>0.983833</td>\n",
       "      <td>0.016167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>epoch=144-val_loss=0.01.ckpt</td>\n",
       "      <td>0.987937</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>0.987937</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>0.987937</td>\n",
       "      <td>0.012063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>epoch=58-val_loss=0.03.ckpt</td>\n",
       "      <td>0.965896</td>\n",
       "      <td>0.034103</td>\n",
       "      <td>0.965896</td>\n",
       "      <td>0.034103</td>\n",
       "      <td>0.965896</td>\n",
       "      <td>0.034103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>epoch=51-val_loss=0.04.ckpt</td>\n",
       "      <td>0.963759</td>\n",
       "      <td>0.036241</td>\n",
       "      <td>0.963759</td>\n",
       "      <td>0.036241</td>\n",
       "      <td>0.963759</td>\n",
       "      <td>0.036241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>epoch=145-val_loss=0.02.ckpt</td>\n",
       "      <td>0.980018</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.980018</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.980018</td>\n",
       "      <td>0.019982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>epoch=112-val_loss=0.01.ckpt</td>\n",
       "      <td>0.986921</td>\n",
       "      <td>0.013079</td>\n",
       "      <td>0.986921</td>\n",
       "      <td>0.013079</td>\n",
       "      <td>0.986921</td>\n",
       "      <td>0.013079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>epoch=67-val_loss=0.03.ckpt</td>\n",
       "      <td>0.969523</td>\n",
       "      <td>0.030477</td>\n",
       "      <td>0.969523</td>\n",
       "      <td>0.030477</td>\n",
       "      <td>0.969523</td>\n",
       "      <td>0.030477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>epoch=142-val_loss=0.01.ckpt</td>\n",
       "      <td>0.992332</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>0.992332</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>0.992332</td>\n",
       "      <td>0.007668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>epoch=147-val_loss=0.02.ckpt</td>\n",
       "      <td>0.981387</td>\n",
       "      <td>0.018613</td>\n",
       "      <td>0.981387</td>\n",
       "      <td>0.018613</td>\n",
       "      <td>0.981387</td>\n",
       "      <td>0.018613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>epoch=148-val_loss=0.03.ckpt</td>\n",
       "      <td>0.971864</td>\n",
       "      <td>0.028136</td>\n",
       "      <td>0.971864</td>\n",
       "      <td>0.028136</td>\n",
       "      <td>0.971864</td>\n",
       "      <td>0.028136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>epoch=149-val_loss=0.03.ckpt</td>\n",
       "      <td>0.971640</td>\n",
       "      <td>0.028360</td>\n",
       "      <td>0.971640</td>\n",
       "      <td>0.028360</td>\n",
       "      <td>0.971640</td>\n",
       "      <td>0.028360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>epoch=71-val_loss=0.03.ckpt</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.027801</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.027801</td>\n",
       "      <td>0.972199</td>\n",
       "      <td>0.027801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>epoch=149-val_loss=0.04.ckpt</td>\n",
       "      <td>0.957198</td>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.957198</td>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.957198</td>\n",
       "      <td>0.042802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>epoch=146-val_loss=0.03.ckpt</td>\n",
       "      <td>0.968669</td>\n",
       "      <td>0.031331</td>\n",
       "      <td>0.968669</td>\n",
       "      <td>0.031331</td>\n",
       "      <td>0.968669</td>\n",
       "      <td>0.031331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>epoch=141-val_loss=0.01.ckpt</td>\n",
       "      <td>0.992863</td>\n",
       "      <td>0.007137</td>\n",
       "      <td>0.992863</td>\n",
       "      <td>0.007137</td>\n",
       "      <td>0.992863</td>\n",
       "      <td>0.007137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>epoch=148-val_loss=0.04.ckpt</td>\n",
       "      <td>0.962613</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.962613</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.962613</td>\n",
       "      <td>0.037387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>epoch=147-val_loss=0.03.ckpt</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>0.032898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>epoch=149-val_loss=0.04.ckpt</td>\n",
       "      <td>0.960003</td>\n",
       "      <td>0.039997</td>\n",
       "      <td>0.960003</td>\n",
       "      <td>0.039997</td>\n",
       "      <td>0.960003</td>\n",
       "      <td>0.039997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>epoch=149-val_loss=0.07.ckpt</td>\n",
       "      <td>0.932378</td>\n",
       "      <td>0.067622</td>\n",
       "      <td>0.932378</td>\n",
       "      <td>0.067622</td>\n",
       "      <td>0.932378</td>\n",
       "      <td>0.067622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>epoch=148-val_loss=0.09.ckpt</td>\n",
       "      <td>0.914410</td>\n",
       "      <td>0.085590</td>\n",
       "      <td>0.914410</td>\n",
       "      <td>0.085590</td>\n",
       "      <td>0.914410</td>\n",
       "      <td>0.085590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>epoch=148-val_loss=0.11.ckpt</td>\n",
       "      <td>0.888208</td>\n",
       "      <td>0.111792</td>\n",
       "      <td>0.888208</td>\n",
       "      <td>0.111792</td>\n",
       "      <td>0.888208</td>\n",
       "      <td>0.111792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>epoch=147-val_loss=0.10.ckpt</td>\n",
       "      <td>0.902048</td>\n",
       "      <td>0.097952</td>\n",
       "      <td>0.902048</td>\n",
       "      <td>0.097952</td>\n",
       "      <td>0.902048</td>\n",
       "      <td>0.097952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc068e4f-eb19-4640-846b-d5e5d96b1917')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-bc068e4f-eb19-4640-846b-d5e5d96b1917 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-bc068e4f-eb19-4640-846b-d5e5d96b1917');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a840dc4e-cf1a-4f5a-a44d-56f354fb1497\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a840dc4e-cf1a-4f5a-a44d-56f354fb1497')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a840dc4e-cf1a-4f5a-a44d-56f354fb1497 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_39ec6354-4443-4459-9cd0-bbc0f80d6e21\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('resultsDF')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_39ec6354-4443-4459-9cd0-bbc0f80d6e21 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('resultsDF');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "resultsDF",
       "summary": "{\n  \"name\": \"resultsDF\",\n  \"rows\": 29,\n  \"fields\": [\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 29,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          28,\n          17,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ModelFile\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"epoch=58-val_loss=0.03.ckpt\",\n          \"epoch=148-val_loss=0.09.ckpt\",\n          \"epoch=144-val_loss=0.01.ckpt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0289490983116108,\n        \"min\": 0.8882080316543579,\n        \"max\": 0.99906986951828,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.8882080316543579,\n          0.9718635678291321,\n          0.9869208931922913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028949093732059773,\n        \"min\": 0.0009301077225245535,\n        \"max\": 0.11179197579622269,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.11179197579622269,\n          0.028136420994997025,\n          0.013079113326966763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0289490983116108,\n        \"min\": 0.8882080316543579,\n        \"max\": 0.99906986951828,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.8882080316543579,\n          0.9718635678291321,\n          0.9869208931922913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028949093732059773,\n        \"min\": 0.0009301077225245535,\n        \"max\": 0.11179197579622269,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.11179197579622269,\n          0.028136420994997025,\n          0.013079113326966763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test R2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0289490983116108,\n        \"min\": 0.8882080316543579,\n        \"max\": 0.99906986951828,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.8882080316543579,\n          0.9718635678291321,\n          0.9869208931922913\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028949093732059773,\n        \"min\": 0.0009301077225245535,\n        \"max\": 0.11179197579622269,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.11179197579622269,\n          0.028136420994997025,\n          0.013079113326966763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "4398bc53fbf63706"
   },
   "cell_type": "code",
   "source": [
    "resultsDF.to_csv(resolve_path_gdrive(f'{CHECKPOINTS_FOLDER}/results.csv'), index=False)"
   ],
   "id": "4398bc53fbf63706",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "2rY85I_NJ8K8"
   },
   "cell_type": "code",
   "source": [
    "dm1 = CatalystDataModule(\n",
    "        data_dir=\"\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        target_num=target\n",
    "    )\n",
    "dm1.prepare_data()\n",
    "dm1.setup()\n",
    "\n",
    "print(r2scoreAndMSE(model, dm1.train_dataloader()))\n",
    "print(r2scoreAndMSE(model, dm1.val_dataloader()))\n",
    "print(r2scoreAndMSE(model, dm1.test_dataloader()))"
   ],
   "id": "2rY85I_NJ8K8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "u1IP95JW5JPT"
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "matrix = np.array([[1, 2, 3, 4],\n",
    "                   [5, 6, 7, 8],\n",
    "                   [9, 10, 11, 12]])\n",
    "m = np.delete(matrix, [-1], axis=1)\n",
    "m"
   ],
   "id": "u1IP95JW5JPT",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "29241ac53cc4e583"
   },
   "cell_type": "markdown",
   "source": [
    "# Learn dataset manipulation\n"
   ],
   "id": "29241ac53cc4e583"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T02:12:23.886846Z",
     "start_time": "2024-11-10T02:12:23.872300Z"
    },
    "id": "3ba1b0344683363e",
    "outputId": "adf313c9-7335-4412-8534-aad3e6d7c1e3"
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class HelloWorldDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = [\"Hello\", \"World\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = HelloWorldDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ],
   "id": "3ba1b0344683363e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello']\n",
      "['World']\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "f5fa3e9ac4fa34f8"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "f5fa3e9ac4fa34f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
