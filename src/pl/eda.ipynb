{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nirb28/nn_catalyst/blob/main/src/pl/eda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "7bfcc695d2bad582"
  },
  {
   "cell_type": "code",
   "source": [
    "def resolve_path_gdrive(relativePath, localPathPrefix=\"\"):\n",
    "    if os.path.exists('/content/drive'):\n",
    "        return '/content/drive/MyDrive/work/gdrive-workspaces/git/nn_catalyst/' + relativePath\n",
    "    else:\n",
    "        return localPathPrefix + relativePath\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fu8JYE9kkLqM",
    "outputId": "1e918600-6cd6-4442-b184-6cb1f115e3ea",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:00:32.451937700Z",
     "start_time": "2024-05-26T22:00:32.353869300Z"
    }
   },
   "id": "Fu8JYE9kkLqM",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import pandas as pd\n",
    "import numpy as np, os\n",
    "\n",
    "# import libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "id": "21adb13e725cc38d",
    "ExecuteTime": {
     "end_time": "2024-05-26T21:58:00.088152900Z",
     "start_time": "2024-05-26T21:57:58.723296900Z"
    }
   },
   "id": "21adb13e725cc38d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Import the dataset from the csv file.\n",
    "df_orig = pd.read_csv(resolve_path_gdrive('src/pl/merged_data_last29.csv', localPathPrefix=\"../\"))"
   ],
   "metadata": {
    "id": "4673c4f52ebdb7bb",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:00:39.418188500Z",
     "start_time": "2024-05-26T22:00:37.590999800Z"
    }
   },
   "id": "4673c4f52ebdb7bb",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# prompt: standard scale all columns of df\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = df_orig.copy()\n",
    "for column in df.columns:\n",
    "  if pd.api.types.is_numeric_dtype(df[column]):\n",
    "    df[column] = scaler.fit_transform(df[[column]])\n",
    "\n"
   ],
   "metadata": {
    "id": "n4RzlTBMNHs4"
   },
   "id": "n4RzlTBMNHs4",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "target_col_name = 'dipole_n'\n",
    "\n",
    "print(df.shape)\n",
    "df_features = df.drop(target_col_name, axis=1)\n",
    "df_target = df[target_col_name]\n",
    "print(df_features.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2010a5e21a9fc812",
    "outputId": "57a87030-6700-49ff-f113-35b2c63feb09",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:00:43.198105900Z",
     "start_time": "2024-05-26T22:00:43.123727800Z"
    }
   },
   "id": "2010a5e21a9fc812",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute the correlation matrix for the first 20 features and the target variable to keep it manageable\n",
    "correlation_matrix = df.iloc[:, 1:21].join(df[target_col_name]).corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Matrix of First 20 Features and Target Variable (ddG)\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "id": "kGSTRh6BmXKV",
    "outputId": "e44c60d1-5ff5-4db4-b05d-c704111d49b0"
   },
   "id": "kGSTRh6BmXKV",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "corr_table = df_features.corrwith(df_target)\n",
    "# prompt: find rows in corr_table where corr > .5\n",
    "high_corr_rows = corr_table[abs(corr_table) > .2]\n",
    "print(len(high_corr_rows.keys()))\n",
    "high_corr_rows.keys()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hejMITQMpSyV",
    "outputId": "8a78759b-af43-4a82-94fd-6f8a80546550",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:01:20.162771800Z",
     "start_time": "2024-05-26T22:01:20.094436400Z"
    }
   },
   "id": "hejMITQMpSyV",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "f = open(resolve_path_gdrive(\"high_corr_cols.txt\"), \"w\")\n",
    "for key in high_corr_rows.keys():\n",
    "  f.write('{},'.format(key))\n",
    "f.close()"
   ],
   "metadata": {
    "id": "m8tRlSgEmQ5S"
   },
   "id": "m8tRlSgEmQ5S",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PCA\n",
    "Here we implement methods that reduce the number of parameters\n"
   ],
   "metadata": {
    "id": "Wl1mloLIDDFB"
   },
   "id": "Wl1mloLIDDFB"
  },
  {
   "cell_type": "code",
   "source": [
    "## Use all columns except target\n",
    "#X = df.drop([target_col_name], axis=1)\n",
    "X = df[df.columns[:-29]]\n",
    "## Use high correlation columns only\n",
    "#X = df[high_corr_rows.keys()]\n",
    "y = df[target_col_name]\n",
    "\n",
    "# import libraires needed to perform our Regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pca = PCA()\n",
    "## Performing PCA on high_corr_keys\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "## Cumulative sum of variance explained by principal components\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "pca_dim = np.argmax(cumsum >= 0.90) + 1\n",
    "print('The number of dimensions required to preserve 90% of variance is', pca_dim)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ec8ME2lhF_Q2",
    "outputId": "260f3f41-953a-40f0-a175-4e778edfcc68",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:01:51.554490600Z",
     "start_time": "2024-05-26T22:01:50.551259700Z"
    }
   },
   "id": "Ec8ME2lhF_Q2",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlim(0,200,1)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "tNFaJlJrJisk",
    "outputId": "9fdbe2c1-7310-4b43-8125-122086c5850f",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:01:53.094117800Z",
     "start_time": "2024-05-26T22:01:52.937508100Z"
    }
   },
   "id": "tNFaJlJrJisk",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components=pca_dim)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgKCpgv7P8uH",
    "outputId": "8515a9a8-8907-446c-fd90-3f6aa5d09b63",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:01:55.608279Z",
     "start_time": "2024-05-26T22:01:55.555237400Z"
    }
   },
   "id": "KgKCpgv7P8uH",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_pca,y,test_size=0.2)\n",
    "for i in [X_train,X_test,y_train,y_test]:\n",
    "    print(\"Shape of Data is {}\".format(i.shape))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOCmtvXAS-wD",
    "outputId": "fad4308a-dff7-4b1c-a827-a281d3aeddaf",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:02:02.672349600Z",
     "start_time": "2024-05-26T22:02:02.636556100Z"
    }
   },
   "id": "XOCmtvXAS-wD",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "model = PLSRegression(n_components=pca_dim)\n",
    "# fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "print('R2 Score is : {} | Root Mean Square Error is : {}'.format(r2,rmse))"
   ],
   "metadata": {
    "id": "PzApLqSZzfnK",
    "outputId": "ea27eb2c-07b4-4014-d170-1e9f7875c040",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-05-26T22:02:38.616665600Z",
     "start_time": "2024-05-26T22:02:38.548976300Z"
    }
   },
   "id": "PzApLqSZzfnK",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## Testing our model\n",
    "tmp_df = y_test.to_frame()\n",
    "tmp_df['pred'] = y_pred.tolist()\n",
    "tmp_df"
   ],
   "metadata": {
    "id": "iZ7KuhPc05Z-",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:05:45.044207Z",
     "start_time": "2024-05-26T22:05:45.023314800Z"
    },
    "outputId": "7330522e-b2c4-414e-ba5f-ef9e89c73f23",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    }
   },
   "id": "iZ7KuhPc05Z-",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# prompt: add polynomial regression to the above code\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# ... (Your existing code) ...\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)  # You can adjust the degree as needed\n",
    "X_poly = poly.fit_transform(X_pca)\n",
    "\n",
    "# Split data into training and testing sets with polynomial features\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y, test_size=0.2)\n",
    "\n",
    "# Create and train a linear regression model using polynomial features\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly, y_train_poly)\n",
    "\n",
    "# Make predictions using the polynomial regression model\n",
    "y_pred_poly = model_poly.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the polynomial regression model\n",
    "r2_poly = r2_score(y_test_poly, y_pred_poly)\n",
    "rmse_poly = np.sqrt(mean_squared_error(y_test_poly, y_pred_poly))\n",
    "\n",
    "print('Polynomial Regression:')\n",
    "print('R2 Score is : {} | Root Mean Square Error is : {}'.format(r2_poly, rmse_poly))\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYYDRcLqSElP",
    "outputId": "bd3ea99c-8e3c-44b9-9862-65700cef7d1a"
   },
   "id": "LYYDRcLqSElP",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "## Testing our model\n",
    "tmp_df_poly = y_test_poly.to_frame()\n",
    "tmp_df_poly['pred'] = y_pred_poly.tolist()\n",
    "tmp_df_poly"
   ],
   "metadata": {
    "id": "BtnwLs47XNPu",
    "outputId": "23aa9cf0-e72e-4b9c-db21-7c3fd3d332f5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    }
   },
   "id": "BtnwLs47XNPu",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# prompt: add polynomial regression to the above code\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# ... (Your existing code) ...\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)  # You can adjust the degree as needed\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "## Performing PCA on high_corr_keys\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "## Cumulative sum of variance explained by principal components\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "pca_dim = np.argmax(cumsum >= 0.90) + 1\n",
    "print('The number of dimensions required to preserve 90% of variance is', pca_dim)\n",
    "# Split data into training and testing sets with polynomial features\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y, test_size=0.2)\n",
    "\n",
    "# Create and train a linear regression model using polynomial features\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly, y_train_poly)\n",
    "\n",
    "# Make predictions using the polynomial regression model\n",
    "y_pred_poly = model_poly.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the polynomial regression model\n",
    "r2_poly = r2_score(y_test_poly, y_pred_poly)\n",
    "rmse_poly = np.sqrt(mean_squared_error(y_test_poly, y_pred_poly))\n",
    "\n",
    "print('Polynomial Regression:')\n",
    "print('R2 Score is : {} | Root Mean Square Error is : {}'.format(r2_poly, rmse_poly))\n",
    "\n"
   ],
   "metadata": {
    "id": "6jZgefAYXbHX"
   },
   "id": "6jZgefAYXbHX",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from joblib import dump, load\n",
    "dump(model, resolve_path_gdrive('models/pls_large.joblib'))\n",
    "clf2 = load(resolve_path_gdrive('models/pls_large.joblib'))"
   ],
   "metadata": {
    "id": "gBVJpV7OWRci",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:05:46.663745200Z",
     "start_time": "2024-05-26T22:05:46.643720500Z"
    }
   },
   "id": "gBVJpV7OWRci",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_pred = df[1:5]\n",
    "X_pred = df_pred[high_corr_rows.keys()]\n",
    "y_pred = df_pred['ddG']\n",
    "y_pred2 = clf2.predict(X_pred)"
   ],
   "metadata": {
    "id": "MtUDV7g0xtrY",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:05:47.347263300Z",
     "start_time": "2024-05-26T22:05:47.327874700Z"
    }
   },
   "id": "MtUDV7g0xtrY",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tmp_df = y_pred.to_frame()\n",
    "tmp_df['pred'] = y_pred2.tolist()\n",
    "tmp_df"
   ],
   "metadata": {
    "id": "NUwaWTuz4waO",
    "outputId": "34c803e1-d606-4b44-9623-1dba80d02a0d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "ExecuteTime": {
     "end_time": "2024-05-26T22:05:48.483874800Z",
     "start_time": "2024-05-26T22:05:48.445710Z"
    }
   },
   "id": "NUwaWTuz4waO",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred2 = clf2.predict(X_pred.iloc[2].to_numpy().reshape(1,-1))"
   ],
   "metadata": {
    "id": "oGkEgKpE5ITb",
    "ExecuteTime": {
     "end_time": "2024-05-26T22:09:06.162043300Z",
     "start_time": "2024-05-26T22:09:06.100082700Z"
    },
    "outputId": "77b7c435-13ca-401b-c49b-5712fce1909f"
   },
   "id": "oGkEgKpE5ITb",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X = df[df.columns[~df.columns.isin(['Catalyst', 'ddG'])]] # high_corr_rows.keys() OR df.columns[~df.columns.isin(['Catalyst', 'ddG'])]\n",
    "y = df['ddG']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "for i in [X_train,X_test,y_train,y_test]:\n",
    "    print(\"Shape of Data is {}\".format(i.shape))\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.0001)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "print('R2 Score is : {} | Root Mean Square Error is : {}'.format(r2,rmse))"
   ],
   "metadata": {
    "id": "ifzUyN04tKhf",
    "outputId": "da94b0bb-f0e9-4eed-fb62-b7c518ef487f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "ifzUyN04tKhf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X = df[df.columns[~df.columns.isin(['Catalyst', 'ddG'])]] # high_corr_rows.keys() OR df.columns[~df.columns.isin(['Catalyst', 'ddG'])]\n",
    "y = df['ddG']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "for i in [X_train,X_test,y_train,y_test]:\n",
    "    print(\"Shape of Data is {}\".format(i.shape))\n",
    "\n",
    "# Lets train our model on training data and predict also on training to see results\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_train)\n",
    "r2 = r2_score(y_train,y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_train,y_pred))\n",
    "print('R-Squared Score is : {} | Root Mean Square Error is : {}'.format(r2,rmse))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DD_Rqd3IV1kK",
    "outputId": "dfd4ca72-171a-4b54-903d-0bff84b07ac3"
   },
   "execution_count": null,
   "id": "DD_Rqd3IV1kK",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Lets train our model on training data and predict on testing to see results\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "print('R2 Score is : {} | Root Mean Square Error is : {}'.format(r2,rmse))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4NGxJ4bV-4G",
    "outputId": "bebb0093-8571-494c-ba37-c1e4ec91773e"
   },
   "execution_count": null,
   "id": "H4NGxJ4bV-4G",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Subset Selection Methods\n",
    "Here we implement methods that reduce the number of parameters\n",
    "\n",
    "### Forward Selection\n",
    "We will  apply the forward-selection approach\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "e1133b03f1e1dec0"
   },
   "id": "e1133b03f1e1dec0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install ISLP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from ISLP.models import \\\n",
    "     (Stepwise,\n",
    "      sklearn_selected,\n",
    "      sklearn_selection_path)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:19:03.335579800Z",
     "start_time": "2024-05-11T22:19:03.211584Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e99f146e021cf452",
    "outputId": "2f63bf8d-1b7e-403e-ca5c-71ad0d6329c8"
   },
   "id": "e99f146e021cf452",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def nCp(sigma2, estimator, X, Y):\n",
    "    \"Negative Cp statistic\"\n",
    "    n, p = X.shape\n",
    "    Yhat = estimator.predict(X)\n",
    "    RSS = np.sum((Y - Yhat)**2)\n",
    "    return -(RSS + 2 * p * sigma2) / n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:19:05.605323Z",
     "start_time": "2024-05-11T22:19:05.525290200Z"
    },
    "id": "147741054fac9033"
   },
   "id": "147741054fac9033",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_cleaned.head()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:19:11.384969700Z",
     "start_time": "2024-05-11T22:19:11.211287400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "76e90585f9f40159",
    "outputId": "73e29d8e-874f-42d2-cfe6-a1949b5414b4"
   },
   "id": "76e90585f9f40159",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first choose the best model using forward selection based on $C_p$. We define a function to compute it as its not built in as a metric to `sklearn`. By default, `sklearn` tries to maximize a score, hence\n",
    "  our scoring function  computes the negative $C_p$ statistic."
   ],
   "metadata": {
    "collapsed": false,
    "id": "84bfb74116b7f5ff"
   },
   "id": "84bfb74116b7f5ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def nCp(sigma2, estimator, X, Y):\n",
    "    \"Negative Cp statistic\"\n",
    "    n, p = X.shape\n",
    "    Yhat = estimator.predict(X)\n",
    "    RSS = np.sum((Y - Yhat)**2)\n",
    "    return -(RSS + 2 * p * sigma2) / n\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:19:30.370069100Z",
     "start_time": "2024-05-11T22:19:30.359070400Z"
    },
    "id": "74a1c39f3bf6c2ba"
   },
   "id": "74a1c39f3bf6c2ba",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "design = MS(df_cleaned.columns.drop('ddG')).fit(df_cleaned)\n",
    "Y = np.array(df_cleaned['ddG'])\n",
    "X = design.transform(df_cleaned)\n",
    "sigma2 = OLS(Y,X).fit().scale"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:19:59.770541Z",
     "start_time": "2024-05-11T22:19:30.372069300Z"
    },
    "id": "5afbbb24e6d51af5"
   },
   "id": "5afbbb24e6d51af5",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "neg_Cp = partial(nCp, sigma2)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:19:59.812541200Z",
     "start_time": "2024-05-11T22:19:59.775545500Z"
    },
    "id": "9b2d89f2a697aa0b"
   },
   "id": "9b2d89f2a697aa0b",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now use `neg_Cp()` as a scorer for model selection.\n",
    "\n",
    "Along with a score we need to specify the search strategy. This is done through the object\n",
    "`Stepwise()`  in the `ISLP.models` package. The method `Stepwise.first_peak()`\n",
    "runs forward stepwise until any further additions to the model do not result\n",
    "in an improvement in the evaluation score. Similarly, the method `Stepwise.fixed_steps()`\n",
    "runs a fixed number of steps of stepwise search."
   ],
   "metadata": {
    "collapsed": false,
    "id": "eb3361bb5c63658d"
   },
   "id": "eb3361bb5c63658d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "strategy = Stepwise.first_peak(design,\n",
    "                               direction='forward',\n",
    "                               max_terms=len(design.terms))\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:19:59.823540600Z",
     "start_time": "2024-05-11T22:19:59.792539300Z"
    },
    "id": "848afb1d0a46242"
   },
   "id": "848afb1d0a46242",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now fit a linear regression model with `Salary` as outcome using forward\n",
    "selection. To do so, we use the function `sklearn_selected()`  from the `ISLP.models` package. This takes\n",
    "a model from `statsmodels` along with a search strategy and selects a model with its\n",
    "`fit` method. Without specifying a `scoring` argument, the score defaults to MSE, and so all 19 variables will be\n",
    "selected."
   ],
   "metadata": {
    "collapsed": false,
    "id": "a035dc5c859106bc"
   },
   "id": "a035dc5c859106bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hitters_MSE = sklearn_selected(OLS,\n",
    "                               strategy)\n",
    "hitters_MSE.fit(df_cleaned, Y)\n",
    "hitters_MSE.selected_state_\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T01:28:19.905487200Z",
     "start_time": "2024-05-09T01:22:44.415589Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5900a71c0efe73de",
    "outputId": "c82a92db-1496-4374-8e90-3d9d873b7f86"
   },
   "id": "5900a71c0efe73de",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using `neg_Cp` results in a smaller model, as expected, with just 10 variables selected."
   ],
   "metadata": {
    "collapsed": false,
    "id": "e390f0e142fca72f"
   },
   "id": "e390f0e142fca72f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hitters_Cp = sklearn_selected(OLS,\n",
    "                               strategy,\n",
    "                               scoring=neg_Cp)\n",
    "hitters_Cp.fit(df_cleaned, Y)\n",
    "hitters_Cp.selected_state_\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T01:36:02.903497600Z",
     "start_time": "2024-05-09T01:28:19.912509700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48853b8ee33f2c63",
    "outputId": "690002bc-a4cf-4edc-bfc7-92cc4aecea61"
   },
   "id": "48853b8ee33f2c63",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choosing Among Models Using the Validation Set Approach and Cross-Validation\n",
    "\n",
    "As an  alternative to using $C_p$, we might try cross-validation to select a model in forward selection. For this, we need a\n",
    "method that stores the full path of models found in forward selection, and allows predictions for each of these. This can be done with the `sklearn_selection_path()`\n",
    "estimator from `ISLP.models`. The function `cross_val_predict()` from `ISLP.models`\n",
    "computes the cross-validated predictions for each of the models\n",
    "along the path, which we can use to evaluate the cross-validated MSE\n",
    "along the path."
   ],
   "metadata": {
    "collapsed": false,
    "id": "396a91f6d0ce6283"
   },
   "id": "396a91f6d0ce6283"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we define a strategy that fits the full forward selection path.\n",
    "While there are various parameter choices for `sklearn_selection_path()`,\n",
    "we use the defaults here, which selects the model at each step based on the biggest reduction  in RSS."
   ],
   "metadata": {
    "collapsed": false,
    "id": "8c04fa80aecb601c"
   },
   "id": "8c04fa80aecb601c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "strategy = Stepwise.fixed_steps(design,\n",
    "                                len(design.terms),\n",
    "                                direction='forward')\n",
    "full_path = sklearn_selection_path(OLS, strategy)\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T22:21:36.057900Z",
     "start_time": "2024-05-11T22:21:35.989656Z"
    },
    "id": "d46736d875a82b97"
   },
   "id": "d46736d875a82b97",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now fit the full forward-selection path on the `Hitters` data and compute the fitted values."
   ],
   "metadata": {
    "collapsed": false,
    "id": "a6b8900c4846c63a"
   },
   "id": "a6b8900c4846c63a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_path.fit(df_cleaned, Y)\n",
    "Yhat_in = full_path.predict(df_cleaned)\n",
    "Yhat_in.shape\n"
   ],
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-11T22:21:50.503839900Z"
    },
    "id": "7c647f43e4dbeb2"
   },
   "id": "7c647f43e4dbeb2",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us an array of fitted values --- 20 steps in all, including the fitted mean for the null model --- which we can use to evaluate\n",
    "in-sample MSE. As expected, the in-sample MSE improves each step we take,\n",
    "indicating we must use either the validation or cross-validation\n",
    "approach to select the number of steps. We fix the y-axis to range from\n",
    "50,000 to 250,000 to compare to the cross-validation and validation\n",
    "set MSE below, as well as other methods such as ridge regression, lasso and\n",
    "principal components regression."
   ],
   "metadata": {
    "collapsed": false,
    "id": "e3625bf7533d0931"
   },
   "id": "e3625bf7533d0931"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mse_fig, ax = subplots(figsize=(8,8))\n",
    "insample_mse = ((Yhat_in - Y[:,None])**2).mean(0)\n",
    "n_steps = insample_mse.shape[0]\n",
    "ax.plot(np.arange(n_steps),\n",
    "        insample_mse,\n",
    "        'k', # color black\n",
    "        label='In-sample')\n",
    "ax.set_ylabel('MSE',\n",
    "              fontsize=20)\n",
    "ax.set_xlabel('# steps of forward stepwise',\n",
    "              fontsize=20)\n",
    "ax.set_xticks(np.arange(n_steps)[::2])\n",
    "ax.legend()\n",
    "ax.set_ylim([50000,250000]);\n"
   ],
   "metadata": {
    "id": "e5a18c9def68fda5"
   },
   "id": "e5a18c9def68fda5",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from ISLP.models import \\\n",
    "     (Stepwise,\n",
    "      sklearn_selected,\n",
    "      sklearn_selection_path)"
   ],
   "metadata": {
    "id": "658daef2fdcf3b1e"
   },
   "id": "658daef2fdcf3b1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
