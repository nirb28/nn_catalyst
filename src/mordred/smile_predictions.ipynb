{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys, os\n",
    "import torch, math, os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Colab!\")\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "else:\n",
    "    print(\"Not running in Colab.\")\n",
    "\n",
    "def resolve_path_gdrive(relativePath):\n",
    "    if os.path.exists('/content/drive'):\n",
    "        return '/content/drive/MyDrive/work/gdrive-workspaces/git/nn_catalyst/' + relativePath\n",
    "    else:\n",
    "        from utils import get_project_root\n",
    "        return get_project_root() + \"/../..\" + relativePath\n",
    "\n",
    "print(f\"Root project folder is at {resolve_path_gdrive('.')}\")\n",
    "\n",
    "CHECKPOINTS_FOLDER_BASE = \"/checkpoints/stn_r3_f849_tlast29/stack=False-scaleY=True\"\n",
    "CHECKPOINTS_FOLDER = resolve_path_gdrive(CHECKPOINTS_FOLDER_BASE) #f'd:/temp{CHECKPOINTS_FOLDER_BASE}'\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.set_float32_matmul_precision(\"medium\")  # to make lightning happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('few_merged_data_f849_tlast29_reordered_byR2.csv')\n",
    "X = df.iloc[:, :849]  # First 849 columns are features\n",
    "y = df.iloc[:, 849:]  # Last 29 columns are targets\n",
    "from pl.model_impl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirbaanm/miniconda3/envs/nn_catalyst_copy/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/nirbaanm/miniconda3/envs/nn_catalyst_copy/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the path to the pickle file\n",
    "pickle_file_path = f'{CHECKPOINTS_FOLDER}/scaler_X.pkl'\n",
    "\n",
    "# Load the StandardScaler from the pickle file\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    scaler = joblib.load(file)\n",
    "\n",
    "# Now you can use the scaler\n",
    "# Example: scaler.transform(data)\n",
    "\n",
    "# Standardize features\n",
    "X_scaled = scaler.transform(X)\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting target 1...\n",
      "Predicting target 2...\n",
      "Predicting target 3...\n",
      "Predicting target 4...\n",
      "Predicting target 5...\n",
      "Predicting target 6...\n",
      "Predicting target 7...\n",
      "Predicting target 8...\n",
      "Predicting target 9...\n",
      "Predicting target 10...\n",
      "Predicting target 11...\n",
      "Predicting target 12...\n",
      "Predicting target 13...\n",
      "Predicting target 14...\n",
      "Predicting target 15...\n",
      "Predicting target 16...\n",
      "Predicting target 17...\n",
      "Predicting target 18...\n",
      "Predicting target 19...\n",
      "Predicting target 20...\n",
      "Predicting target 21...\n",
      "Predicting target 22...\n",
      "Predicting target 23...\n",
      "Predicting target 24...\n",
      "Predicting target 25...\n",
      "Predicting target 26...\n",
      "Predicting target 27...\n",
      "Predicting target 28...\n",
      "Predicting target 29...\n",
      "Predictions shape: (8, 29)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def eval_model(X_data, target_num):\n",
    "    X_scaled = scaler.transform(X_data)\n",
    "    X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "    checkpoint_path=f'{CHECKPOINTS_FOLDER}/{target_num}'\n",
    "    pathlist = Path(checkpoint_path).glob('**/*.ckpt')\n",
    "    for path in pathlist:\n",
    "        # because path is object not string\n",
    "        model = SingleTargetNet.load_from_checkpoint(str(path))\n",
    "        model.eval()\n",
    "        model.cpu()\n",
    "        with torch.no_grad():\n",
    "                y_pred = model(X_tensor)\n",
    "        return y_pred.detach().numpy()\n",
    "        \n",
    "# Load models and make predictions\n",
    "predictions = []\n",
    "for target_index in range(df.shape[1] - 849):\n",
    "    print(f\"Predicting target {target_index + 1}...\")\n",
    "    predictions.append(eval_model(X_tensor, target_index+1))\n",
    "    \n",
    "# Stack predictions into array\n",
    "predictions = np.hstack(predictions)\n",
    "\n",
    "# Create a DataFrame for predictions\n",
    "#predictions_df = pd.DataFrame(predictions, columns=[f'Prediction_{i}' for i in range(predictions.shape[1])])\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "#predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38041747,  0.37435395,  0.38301158,  0.32179022,  0.40278733,\n",
       "         0.35184574, -1.5712007 , -1.3984663 ,  1.5064232 ,  2.4844203 ,\n",
       "         1.7189146 ,  2.7789712 ,  1.8699226 ,  1.3264762 , -1.1213297 ,\n",
       "        -1.8684686 ,  1.3493798 ,  1.7378752 , -0.16221514, -1.998511  ,\n",
       "        -1.7195978 , -0.73782766,  1.1627886 , -1.9192525 ,  2.836595  ,\n",
       "         0.8197746 ,  0.3535876 , -0.40010872, -0.70075166],\n",
       "       [ 0.25580525,  0.2529648 ,  0.2503891 ,  0.28139862,  0.30164066,\n",
       "         0.28221887, -0.6387827 , -0.69388795,  0.50233024,  0.11119656,\n",
       "        -0.03374834,  2.4412274 ,  2.7798343 ,  0.27203688, -0.5255129 ,\n",
       "        -0.8286061 ,  0.28920034,  2.1548796 ,  0.62466604, -1.1175022 ,\n",
       "        -1.1320281 ,  0.4210174 , -0.75317067, -1.1652302 ,  0.01175366,\n",
       "         1.3295193 , -0.41899648,  0.39197096,  1.3291682 ],\n",
       "       [ 0.81967187,  0.8394152 ,  0.8660329 ,  0.8326798 ,  0.8342287 ,\n",
       "         0.82582533, -1.8965763 , -2.0378969 ,  1.4113448 ,  0.43807143,\n",
       "        -1.1920977 , -1.1741518 , -0.8855235 ,  1.3014976 , -1.7830007 ,\n",
       "        -0.97969306,  1.9194825 , -1.2412913 ,  2.171077  , -0.61159503,\n",
       "        -0.4228475 ,  1.5852953 ,  1.1027554 , -0.02013563,  0.3045049 ,\n",
       "         0.47502604, -0.97737974, -0.38858113, -0.18899809],\n",
       "       [ 0.49533346,  0.48181164,  0.5095004 ,  0.4910899 ,  0.5076731 ,\n",
       "         0.47647268, -1.5292898 , -1.5773866 ,  1.3862916 , -0.4820851 ,\n",
       "        -1.4945015 , -0.0864376 , -0.06161753,  0.18343793, -1.4320297 ,\n",
       "        -1.1792052 ,  1.3520436 , -0.20649688,  0.9856498 ,  0.21220312,\n",
       "         0.24069646,  0.72509104,  0.5740617 ,  0.12027083,  0.3694242 ,\n",
       "         0.09230259, -0.81912786, -0.57310045, -0.1026327 ],\n",
       "       [-1.6379724 , -1.6111859 , -1.6809148 , -1.6915774 , -1.6314906 ,\n",
       "        -1.6642909 , -0.6409024 , -0.21392699,  0.04129968,  0.29490668,\n",
       "        -0.10989334, -0.3678073 , -0.47507554, -0.09415894, -0.13516158,\n",
       "         0.28727338, -0.15892458, -0.35531092, -0.31184006,  0.01243632,\n",
       "        -0.4024605 , -1.0147994 ,  0.35724252, -0.7624563 ,  1.3227245 ,\n",
       "         1.084116  ,  0.39102685, -0.07998186, -0.4506312 ],\n",
       "       [-0.5947743 , -0.60599345, -0.59143966, -0.57887715, -0.5630837 ,\n",
       "        -0.62927824,  0.62910324,  0.6379408 , -0.66998607, -0.24041654,\n",
       "         0.41177484, -0.530262  , -0.58579916, -0.4676676 ,  0.8995351 ,\n",
       "         0.60242295, -0.7786142 , -0.34249634, -0.49937835,  0.6521441 ,\n",
       "         0.7128148 , -0.2768105 ,  0.2985224 ,  1.2672822 ,  0.32414874,\n",
       "         1.8139292 , -0.3483554 , -0.0845692 ,  0.09857891],\n",
       "       [-1.9706194 , -1.9451686 , -1.9334643 , -1.8541604 , -1.838223  ,\n",
       "        -1.8522701 , -0.3750275 , -0.37624663,  0.510038  ,  0.2705891 ,\n",
       "        -0.03648767,  0.01634053,  0.09743318, -0.13267277, -0.34182552,\n",
       "        -0.5887708 , -0.71296406, -0.3654391 , -0.39964318, -0.40337157,\n",
       "        -0.3230964 , -0.9445169 , -0.20067415, -0.77669   ,  1.6097353 ,\n",
       "        -0.88430774,  0.2408641 , -0.7216159 , -0.611142  ],\n",
       "       [ 0.5119905 ,  0.52717954,  0.49071938,  0.5421254 ,  0.55192524,\n",
       "         0.5314241 , -0.4987405 , -0.34417287,  0.2752614 ,  0.18020333,\n",
       "        -0.44735005,  0.64371836,  0.64120823,  0.28791422, -0.26350322,\n",
       "        -0.34224522, -0.02568275,  0.62492645,  0.38196218, -1.1268548 ,\n",
       "        -0.9616539 ,  0.5087994 ,  0.07231302, -1.0208689 , -0.51426125,\n",
       "        -0.37113684, -0.8298363 , -0.81312335, -0.33390623]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns in descriptors_df: ['SMILES', mordred.ABCIndex.ABCIndex(), mordred.ABCIndex.ABCGGIndex(), mordred.GeometricalIndex.Diameter3D(), mordred.GeometricalIndex.Radius3D(), mordred.GeometricalIndex.GeometricalShapeIndex(), mordred.GeometricalIndex.PetitjeanIndex3D(), mordred.GravitationalIndex.GravitationalIndex(True, False), mordred.GravitationalIndex.GravitationalIndex(True, True), mordred.MoRSE.MoRSE(None, 1), mordred.MoRSE.MoRSE('m', 1), mordred.MoRSE.MoRSE('v', 1), mordred.MoRSE.MoRSE('p', 1), mordred.MomentOfInertia.MomentOfInertia('X'), mordred.MomentOfInertia.MomentOfInertia('Y'), mordred.MomentOfInertia.MomentOfInertia('Z'), mordred.PBF.PBF()]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "\n",
    "def generate_mordred_descriptors(smiles_list, columns=None):\n",
    "    \"\"\"\n",
    "    Generate Mordred descriptors for a list of SMILES strings.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    smiles_list : list\n",
    "        List of SMILES strings to calculate descriptors for\n",
    "    columns : list, optional\n",
    "        List of specific columns to include\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing molecular descriptors for each SMILES string\n",
    "    \"\"\"\n",
    "    # Create a calculator with all available descriptors\n",
    "    calc = Calculator(descriptors)\n",
    "    \n",
    "    # If columns are specified, filter the descriptors\n",
    "    if columns:\n",
    "        # Filter descriptors to match the specified columns\n",
    "        filtered_descriptors = [desc for desc in calc.descriptors if str(desc) in columns]\n",
    "        calc = Calculator(filtered_descriptors)\n",
    "    \n",
    "    # Prepare results\n",
    "    results = []\n",
    "    \n",
    "    # Calculate descriptors for each SMILES string\n",
    "    for smiles in smiles_list:\n",
    "        # Convert SMILES to RDKit molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "        if mol is not None:\n",
    "            # Calculate descriptors\n",
    "            try:\n",
    "                desc_values = calc(mol)\n",
    "                # Convert to dictionary, adding SMILES as first column\n",
    "                desc_dict = {'SMILES': smiles, **dict(desc_values)}\n",
    "                results.append(desc_dict)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating descriptors for {smiles}: {e}\")\n",
    "        else:\n",
    "            print(f\"Invalid SMILES string: {smiles}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Ensure all specified columns are present, fill with NaN if missing\n",
    "    # if columns:\n",
    "    #     for col in columns:\n",
    "    #         if col not in df.columns:\n",
    "    #             df[col] = np.nan\n",
    "        \n",
    "    #     # Reorder columns to match the original specification\n",
    "    #     df = df[['SMILES'] + [col for col in columns if col != 'SMILES']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def read_descriptors(file_path):\n",
    "    \"\"\"\n",
    "    Read the descriptors from a file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the file containing column names\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of column names\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Read the first line and split by tab\n",
    "        columns = f.readline().strip().split('\\t')\n",
    "    return columns\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    smiles_list = [\n",
    "        'CC(=O)OC1=CC=CC=C1C(=O)O',  # Aspirin\n",
    "        'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',  # Caffeine\n",
    "        'CC(C)(C)NCC(O)C1=CC(=C(C=C1)O)CO'  # Salbutamol\n",
    "    ]\n",
    "    \n",
    "    # Generate descriptors\n",
    "    descriptors_df = generate_mordred_descriptors(smiles_list)\n",
    "    \n",
    "    # Read the descriptors from descriptors.txt\n",
    "    descriptors_file_path = 'descriptors.txt'\n",
    "    descriptors = read_descriptors(descriptors_file_path)\n",
    "    \n",
    "    # Filter the columns to keep only those present in descriptors.txt\n",
    "    filtered_descriptors_df = descriptors_df#[descriptors]\n",
    "    \n",
    "    # Print first few rows and basic info\n",
    "    print(filtered_descriptors_df)\n",
    "    print(\"\\nTotal descriptors calculated:\", len(filtered_descriptors_df.columns) - 1)  # -1 for SMILES column\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()\n",
    "# Example usage\n",
    "smiles_list = [\n",
    "    'CC(=O)OC1=CC=CC=C1C(=O)O',  # Aspirin\n",
    "    'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',  # Caffeine\n",
    "    'CC(C)(C)NCC(O)C1=CC(=C(C=C1)O)CO'  # Salbutamol\n",
    "]\n",
    "\n",
    "features_file_path = 'descriptors.txt'\n",
    "features = read_descriptors(features_file_path)\n",
    "# Generate descriptors\n",
    "descriptors_df = generate_mordred_descriptors(smiles_list, features)\n",
    "non_numeric_columns = descriptors_df.select_dtypes(exclude=[np.number]).columns\n",
    "print(\"Non-numeric columns in descriptors_df:\", non_numeric_columns.tolist())\n",
    "filled_descriptors_df = descriptors_df.apply(pd.to_numeric, errors='coerce').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCGG</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>nAromAtom</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>nHeavyAtom</th>\n",
       "      <th>nSpiro</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW09</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.151333</td>\n",
       "      <td>43.556121</td>\n",
       "      <td>180.042259</td>\n",
       "      <td>8.573441</td>\n",
       "      <td>246</td>\n",
       "      <td>16</td>\n",
       "      <td>60.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.842683</td>\n",
       "      <td>9.824498</td>\n",
       "      <td>60.521485</td>\n",
       "      <td>194.080376</td>\n",
       "      <td>8.086682</td>\n",
       "      <td>258</td>\n",
       "      <td>25</td>\n",
       "      <td>76.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.519662</td>\n",
       "      <td>49.239030</td>\n",
       "      <td>239.152144</td>\n",
       "      <td>6.293477</td>\n",
       "      <td>560</td>\n",
       "      <td>22</td>\n",
       "      <td>82.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.763889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SMILES  ABC  ABCGG  nAcid  nBase  nAromAtom  nAromBond  nAtom  nHeavyAtom  \\\n",
       "0     0.0  0.0    0.0      1      0          6          6     21          13   \n",
       "1     0.0  0.0    0.0      0      0          9         10     24          14   \n",
       "2     0.0  0.0    0.0      0      1          6          6     38          17   \n",
       "\n",
       "   nSpiro  ...     SRW09     SRW10     TSRW10          MW       AMW  WPath  \\\n",
       "0       0  ...  0.000000  9.151333  43.556121  180.042259  8.573441    246   \n",
       "1       0  ...  6.842683  9.824498  60.521485  194.080376  8.086682    258   \n",
       "2       0  ...  0.000000  9.519662  49.239030  239.152144  6.293477    560   \n",
       "\n",
       "   WPol  Zagreb1  Zagreb2  mZagreb2  \n",
       "0    16     60.0     66.0  2.972222  \n",
       "1    25     76.0     94.0  3.027778  \n",
       "2    22     82.0     90.0  3.763889  \n",
       "\n",
       "[3 rows x 850 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_descriptors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting target 1...\n",
      "Predicting target 2...\n",
      "Predicting target 3...\n",
      "Predicting target 4...\n",
      "Predicting target 5...\n",
      "Predicting target 6...\n",
      "Predicting target 7...\n",
      "Predicting target 8...\n",
      "Predicting target 9...\n",
      "Predicting target 10...\n",
      "Predicting target 11...\n",
      "Predicting target 12...\n",
      "Predicting target 13...\n",
      "Predicting target 14...\n",
      "Predicting target 15...\n",
      "Predicting target 16...\n",
      "Predicting target 17...\n",
      "Predicting target 18...\n",
      "Predicting target 19...\n",
      "Predicting target 20...\n",
      "Predicting target 21...\n",
      "Predicting target 22...\n",
      "Predicting target 23...\n",
      "Predicting target 24...\n",
      "Predicting target 25...\n",
      "Predicting target 26...\n",
      "Predicting target 27...\n",
      "Predicting target 28...\n",
      "Predicting target 29...\n",
      "Predictions shape: (3, 29)\n"
     ]
    }
   ],
   "source": [
    "X = filled_descriptors_df.iloc[:, 1:]\n",
    "# Load models and make predictions\n",
    "predictions = []\n",
    "for target_index in range(0,29):\n",
    "    print(f\"Predicting target {target_index + 1}...\")\n",
    "    predictions.append(eval_model(X, target_index+1))\n",
    "    \n",
    "# Stack predictions into array\n",
    "predictions = np.hstack(predictions)\n",
    "\n",
    "# Create a DataFrame for predictions\n",
    "#predictions_df = pd.DataFrame(predictions, columns=[f'Prediction_{i}' for i in range(predictions.shape[1])])\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "#predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64802194,  0.6763011 ,  0.6720045 ,  0.67016065,  0.67170584,\n",
       "         0.6552182 , -0.82114154, -0.9100838 ,  0.6595404 , -0.5081216 ,\n",
       "        -1.0814366 ,  0.05959841,  0.02388677, -0.18653761, -0.69126606,\n",
       "        -0.24044074,  0.29728162, -0.13252875,  0.17962259,  0.1698237 ,\n",
       "         0.29177457, -0.04388487,  0.883669  ,  0.07067779, -0.20569256,\n",
       "         0.5556835 , -0.10551096, -0.44832402,  0.04236376],\n",
       "       [ 0.6738402 ,  0.6561382 ,  0.63686115,  0.6457978 ,  0.61609817,\n",
       "         0.63263655, -0.44888505, -0.16474499, -0.28109866,  0.45998436,\n",
       "        -0.6971879 , -0.75150657, -0.8275612 ,  0.5387262 ,  0.33591998,\n",
       "         1.2273989 ,  1.262187  , -0.8855711 ,  0.67656326,  0.19945568,\n",
       "         0.03132928,  0.5865191 ,  1.3763336 ,  0.25950426,  0.4072792 ,\n",
       "         0.4472001 , -0.29103306, -0.63100445,  0.14188881],\n",
       "       [ 0.5220504 ,  0.49777406,  0.5086727 ,  0.540165  ,  0.5316565 ,\n",
       "         0.5020793 ,  0.5621456 ,  0.9338471 , -0.8875675 ,  0.7965739 ,\n",
       "         0.97173667,  0.03754257, -0.03346382,  0.93983734,  1.0699437 ,\n",
       "         1.0024563 ,  0.86170894,  0.01148605,  0.67928374, -0.89160115,\n",
       "        -0.84975725,  0.80333513,  0.8450994 , -0.9538265 ,  0.00320481,\n",
       "         0.85630995,  0.09732063, -0.74438035, -0.32009402]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_catalyst_copy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
